{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/tutorials/3-Practical/FinRL_PaperTrading_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1ofncK2cYhs"
   },
   "source": [
    "Disclaimer: Nothing herein is financial advice, and NOT a recommendation to trade real money. Many platforms exist for simulated trading (paper trading) which can be used for building and developing the methods discussed. Please use common sense and always first consult a professional before trading or investing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3mbRu3s1YlD"
   },
   "source": [
    "# Part 1: Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gkmsPgbvNf6",
    "outputId": "d421a902-2eab-4cd8-f842-bfb5ad3b3fef"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--6Kx8I21erH"
   },
   "source": [
    "## Import related modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7I7zsyYfoLJ",
    "outputId": "73fd67c1-222c-450c-a51d-eea50e3a5eeb"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'finrl.finrl_meta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_tickers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DOW_30_TICKER\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INDICATORS\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinrl_meta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_stock_trading\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_stocktrading_np\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StockTradingEnv\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinrl_meta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_stock_trading\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_stock_papertrading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlpacaPaperTrading\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinrl_meta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataProcessor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'finrl.finrl_meta'"
     ]
    }
   ],
   "source": [
    "from finrl.train import train\n",
    "from finrl.test import test\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.finrl.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
    "from finrl.finrl.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\n",
    "from finrl.finrl.data_processor import DataProcessor\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "logger = logging.getLogger('notebook')\n",
    "\n",
    "logger.info('Protocol problem: %s', 'connection reset')\n",
    "\n",
    "# install ipywidgets to fix the jupyter notebook warning\n",
    "# D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf5aVHAU-xF6"
   },
   "source": [
    "## Import Dow Jones 30 Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jx25TA_X87F-"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DOW_30_TICKER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ticker_list \u001b[38;5;241m=\u001b[39m \u001b[43mDOW_30_TICKER\u001b[49m\n\u001b[0;32m      2\u001b[0m action_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(DOW_30_TICKER)\n\u001b[0;32m      3\u001b[0m candle_time_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15Min\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DOW_30_TICKER' is not defined"
     ]
    }
   ],
   "source": [
    "ticker_list = DOW_30_TICKER\n",
    "action_dim = len(DOW_30_TICKER)\n",
    "candle_time_interval = '15Min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIV0kO_y-inG",
    "outputId": "4892aec0-cf63-43d7-c114-ed2fc8b5588c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ticker_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mticker_list\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ticker_list' is not defined"
     ]
    }
   ],
   "source": [
    "print(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnqQ-cC5-rfO",
    "outputId": "e84ce69a-c049-4c2f-e17d-22a13f6b4789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
     ]
    }
   ],
   "source": [
    "print(INDICATORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZMkcyjZ-25l"
   },
   "source": [
    "## Calculate the DRL state dimension manually for paper trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GLfkTsXK-e90"
   },
   "outputs": [],
   "source": [
    "# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\n",
    "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqUkvImG-n66",
    "outputId": "1b9f80c8-ef04-4138-9ab5-6bab406d8d1b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstate_dim\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state_dim' is not defined"
     ]
    }
   ],
   "source": [
    "state_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rwy7V72-8YY"
   },
   "source": [
    "## Get the API Keys Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8Z6qlLXY-fA2"
   },
   "outputs": [],
   "source": [
    "API_KEY = \"PKZOWRCNANQ79J7CV314\"\n",
    "API_SECRET = \"7xYTpMGdeffzOsDDsrnl4UryzvJClIpsvZeTIPYf\"\n",
    "API_BASE_URL = 'https://paper-api.alpaca.markets'\n",
    "data_url = 'wss://data.alpaca.markets'\n",
    "env = StockTradingEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J25MuZLiGqCP"
   },
   "source": [
    "## Show the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puJZWm8NHtSN"
   },
   "source": [
    "### Step 1. Pick a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZCru8f7GqgL",
    "outputId": "7c227e80-674e-4aba-df1a-be130fd65b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca successfully connected\n"
     ]
    }
   ],
   "source": [
    "DP = DataProcessor(data_source = 'alpaca',\n",
    "                  API_KEY = API_KEY, \n",
    "                  API_SECRET = API_SECRET, \n",
    "                  API_BASE_URL = API_BASE_URL\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvPEW2mYHvkR"
   },
   "source": [
    "### Step 2. Get ticker list, Set start date and end date, specify the data frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPNxj6c8HIiE",
    "outputId": "72c38958-3beb-44da-94e3-04f342599539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 18:57:17 [INFO] notebook - Data before 2018-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:21 [INFO] notebook - Data before 2018-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:24 [INFO] notebook - Data before 2018-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:28 [INFO] notebook - Data before 2018-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:32 [INFO] notebook - Data before 2018-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:35 [INFO] notebook - Data before 2018-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:38 [INFO] notebook - Data before 2018-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:42 [INFO] notebook - Data before 2018-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:46 [INFO] notebook - Data before 2018-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:50 [INFO] notebook - Data before 2018-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:54 [INFO] notebook - Data before 2018-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:57:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 18:58:00 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 18:58:04 [INFO] notebook - Data before 2018-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:05 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 18:58:10 [INFO] notebook - Data before 2018-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 18:58:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 18:58:20 [INFO] notebook - Data before 2018-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 18:58:25 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 18:58:30 [INFO] notebook - Data before 2018-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 18:58:36 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 18:58:40 [INFO] notebook - Data before 2018-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:42 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 18:58:47 [INFO] notebook - Data before 2018-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:48 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 18:58:53 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 18:58:57 [INFO] notebook - Data before 2018-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:58:59 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 18:59:04 [INFO] notebook - Data before 2018-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:59:04 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 18:59:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 18:59:14 [INFO] notebook - Data before 2018-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:59:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 18:59:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 18:59:24 [INFO] notebook - Data before 2018-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:59:25 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 18:59:30 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 18:59:34 [INFO] notebook - Data before 2018-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:59:36 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 18:59:42 [INFO] notebook - Data before 2018-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:59:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 18:59:49 [INFO] notebook - Data before 2018-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 18:59:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 18:59:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 18:59:59 [INFO] notebook - Data before 2018-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:00 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:00:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:00:10 [INFO] notebook - Data before 2018-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:11 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:00:16 [INFO] notebook - Data before 2018-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:00:21 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:00:26 [INFO] notebook - Data before 2018-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:27 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:00:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:00:36 [INFO] notebook - Data before 2018-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:38 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:00:43 [INFO] notebook - Data before 2018-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:00:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:00:54 [INFO] notebook - Data before 2018-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:00:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:01:01 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:01:04 [INFO] notebook - Data before 2018-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:07 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:01:12 [INFO] notebook - Data before 2018-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:12 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:01:18 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:01:21 [INFO] notebook - Data before 2018-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:01:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:01:31 [INFO] notebook - Data before 2018-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:01:39 [INFO] notebook - Data before 2018-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:40 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:01:46 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:01:49 [INFO] notebook - Data before 2018-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:01:57 [INFO] notebook - Data before 2018-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:01:58 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:02:06 [INFO] notebook - Data before 2018-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:07 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:02:13 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:02:16 [INFO] notebook - Data before 2018-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:18 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:02:23 [INFO] notebook - Data before 2018-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:02:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:02:33 [INFO] notebook - Data before 2018-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:02:40 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DOW/bars 3 more time(s)...\n",
      "2022-07-20 19:02:43 [INFO] notebook - Data before 2018-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:46 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:02:51 [INFO] notebook - Data before 2018-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:02:58 [INFO] notebook - Data before 2018-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:02:59 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:03:05 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:03:09 [INFO] notebook - Data before 2018-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:03:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:03:16 [INFO] notebook - Data before 2018-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:03:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:03:22 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:03:26 [INFO] notebook - Data before 2018-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:03:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:03:33 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:03:37 [INFO] notebook - Data before 2018-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:03:39 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:03:44 [INFO] notebook - Data before 2018-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:03:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:03:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:03:54 [INFO] notebook - Data before 2018-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:03:57 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:04:02 [INFO] notebook - Data before 2018-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:04:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:04:08 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:04:12 [INFO] notebook - Data before 2018-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:04:14 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:04:20 [INFO] notebook - Data before 2018-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:04:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:04:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:04:30 [INFO] notebook - Data before 2018-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:04:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:04:37 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:04:40 [INFO] notebook - Data before 2018-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:04:43 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:04:48 [INFO] notebook - Data before 2018-02-26T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:04:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:04:55 [INFO] notebook - Data before 2018-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:04:56 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:05:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:05:06 [INFO] notebook - Data before 2018-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:05:08 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:05:13 [INFO] notebook - Data before 2018-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:05:14 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:05:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:05:24 [INFO] notebook - Data before 2018-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:05:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JNJ/bars 3 more time(s)...\n",
      "2022-07-20 19:05:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DOW/bars 3 more time(s)...\n",
      "2022-07-20 19:05:34 [INFO] notebook - Data before 2018-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:05:37 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:05:41 [INFO] notebook - Data before 2018-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:05:42 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:05:49 [INFO] notebook - Data before 2018-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:05:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:05:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:06:00 [INFO] notebook - Data before 2018-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:06:01 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:06:07 [INFO] notebook - Data before 2018-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:06:07 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:06:13 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:06:18 [INFO] notebook - Data before 2018-03-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:06:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JNJ/bars 3 more time(s)...\n",
      "2022-07-20 19:06:26 [INFO] notebook - Data before 2018-03-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:06:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:06:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:06:36 [INFO] notebook - Data before 2018-03-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:06:37 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:06:43 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:06:46 [INFO] notebook - Data before 2018-03-11T16:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:06:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:06:54 [INFO] notebook - Data before 2018-03-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:06:56 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:07:02 [INFO] notebook - Data before 2018-03-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:07:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:07:08 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:07:12 [INFO] notebook - Data before 2018-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:07:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:07:20 [INFO] notebook - Data before 2018-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:07:21 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:07:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DOW/bars 3 more time(s)...\n",
      "2022-07-20 19:07:31 [INFO] notebook - Data before 2018-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:07:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:07:38 [INFO] notebook - Data before 2018-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:07:39 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:07:46 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:07:49 [INFO] notebook - Data before 2018-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:07:54 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:07:58 [INFO] notebook - Data before 2018-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:08:00 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MMM/bars 3 more time(s)...\n",
      "2022-07-20 19:08:05 [INFO] notebook - Data before 2018-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:08:07 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:08:13 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DOW/bars 3 more time(s)...\n",
      "2022-07-20 19:08:16 [INFO] notebook - Data before 2018-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:08:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:08:24 [INFO] notebook - Data before 2018-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:08:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:08:32 [INFO] notebook - Data before 2018-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:08:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:08:38 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:08:42 [INFO] notebook - Data before 2018-03-24T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:08:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:08:50 [INFO] notebook - Data before 2018-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:08:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:08:57 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:09:01 [INFO] notebook - Data before 2018-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:04 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:09:08 [INFO] notebook - Data before 2018-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:11 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:09:17 [INFO] notebook - Data before 2018-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:09:24 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:09:28 [INFO] notebook - Data before 2018-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:30 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:09:35 [INFO] notebook - Data before 2018-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:36 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:09:42 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:09:46 [INFO] notebook - Data before 2018-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:48 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:09:53 [INFO] notebook - Data before 2018-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:09:54 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:10:02 [INFO] notebook - Data before 2018-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:10:10 [INFO] notebook - Data before 2018-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:10:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:10:21 [INFO] notebook - Data before 2018-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:10:29 [INFO] notebook - Data before 2018-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:30 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:10:37 [INFO] notebook - Data before 2018-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:38 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:10:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:10:48 [INFO] notebook - Data before 2018-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:10:55 [INFO] notebook - Data before 2018-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:10:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:11:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:11:07 [INFO] notebook - Data before 2018-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:11:09 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MMM/bars 3 more time(s)...\n",
      "2022-07-20 19:11:15 [INFO] notebook - Data before 2018-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:11:16 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:11:23 [INFO] notebook - Data before 2018-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:11:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:11:30 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:11:34 [INFO] notebook - Data before 2018-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:11:37 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:11:42 [INFO] notebook - Data before 2018-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:11:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:11:50 [INFO] notebook - Data before 2018-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:11:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:11:56 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:12:00 [INFO] notebook - Data before 2018-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:12:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MMM/bars 3 more time(s)...\n",
      "2022-07-20 19:12:09 [INFO] notebook - Data before 2018-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:12:12 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:12:17 [INFO] notebook - Data before 2018-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:12:19 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:12:25 [INFO] notebook - Data before 2018-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:12:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:12:33 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:12:37 [INFO] notebook - Data before 2018-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:12:41 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:12:45 [INFO] notebook - Data before 2018-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:12:47 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:12:53 [INFO] notebook - Data before 2018-04-21T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:12:53 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:13:00 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:13:04 [INFO] notebook - Data before 2018-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:09 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:13:13 [INFO] notebook - Data before 2018-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:16 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:13:21 [INFO] notebook - Data before 2018-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JNJ/bars 3 more time(s)...\n",
      "2022-07-20 19:13:29 [INFO] notebook - Data before 2018-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:13:37 [INFO] notebook - Data before 2018-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:38 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:13:45 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:13:49 [INFO] notebook - Data before 2018-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:13:57 [INFO] notebook - Data before 2018-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:13:59 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:14:05 [INFO] notebook - Data before 2018-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:14:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:14:13 [INFO] notebook - Data before 2018-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:14:13 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:14:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:14:24 [INFO] notebook - Data before 2018-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:14:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:14:33 [INFO] notebook - Data before 2018-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:14:35 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:14:41 [INFO] notebook - Data before 2018-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:14:43 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:14:49 [INFO] notebook - Data before 2018-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:14:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:14:57 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:15:01 [INFO] notebook - Data before 2018-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:15:08 [INFO] notebook - Data before 2018-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:15:17 [INFO] notebook - Data before 2018-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:18 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:15:25 [INFO] notebook - Data before 2018-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:25 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:15:33 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:15:37 [INFO] notebook - Data before 2018-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:40 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:15:45 [INFO] notebook - Data before 2018-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:48 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:15:54 [INFO] notebook - Data before 2018-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:15:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:16:02 [INFO] notebook - Data before 2018-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:16:09 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:16:13 [INFO] notebook - Data before 2018-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:16:21 [INFO] notebook - Data before 2018-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:25 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:16:30 [INFO] notebook - Data before 2018-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:16:39 [INFO] notebook - Data before 2018-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:40 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:16:47 [INFO] notebook - Data before 2018-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:48 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:16:56 [INFO] notebook - Data before 2018-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:16:57 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:17:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:17:07 [INFO] notebook - Data before 2018-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:17:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:17:15 [INFO] notebook - Data before 2018-05-20T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:17:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:17:24 [INFO] notebook - Data before 2018-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:17:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JNJ/bars 3 more time(s)...\n",
      "2022-07-20 19:17:32 [INFO] notebook - Data before 2018-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:17:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:17:41 [INFO] notebook - Data before 2018-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:17:42 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:17:50 [INFO] notebook - Data before 2018-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:17:51 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:17:59 [INFO] notebook - Data before 2018-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:17:59 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:18:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:18:10 [INFO] notebook - Data before 2018-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:18:13 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:18:18 [INFO] notebook - Data before 2018-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:18:21 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:18:26 [INFO] notebook - Data before 2018-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:18:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:18:35 [INFO] notebook - Data before 2018-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:18:38 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:18:44 [INFO] notebook - Data before 2018-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:18:46 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:18:53 [INFO] notebook - Data before 2018-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:18:54 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:19:02 [INFO] notebook - Data before 2018-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:19:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:19:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:19:13 [INFO] notebook - Data before 2018-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:19:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:19:22 [INFO] notebook - Data before 2018-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:19:27 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:19:31 [INFO] notebook - Data before 2018-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:19:35 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CRM/bars 3 more time(s)...\n",
      "2022-07-20 19:19:40 [INFO] notebook - Data before 2018-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:19:45 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:19:49 [INFO] notebook - Data before 2018-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:19:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:19:58 [INFO] notebook - Data before 2018-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:20:07 [INFO] notebook - Data before 2018-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:11 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:20:15 [INFO] notebook - Data before 2018-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:18 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:20:24 [INFO] notebook - Data before 2018-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JNJ/bars 3 more time(s)...\n",
      "2022-07-20 19:20:33 [INFO] notebook - Data before 2018-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:35 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:20:41 [INFO] notebook - Data before 2018-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JNJ/bars 3 more time(s)...\n",
      "2022-07-20 19:20:50 [INFO] notebook - Data before 2018-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:20:53 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:20:59 [INFO] notebook - Data before 2018-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:01 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:21:08 [INFO] notebook - Data before 2018-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:21:17 [INFO] notebook - Data before 2018-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:18 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:21:25 [INFO] notebook - Data before 2018-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:26 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:21:34 [INFO] notebook - Data before 2018-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:35 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:21:44 [INFO] notebook - Data before 2018-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:21:53 [INFO] notebook - Data before 2018-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:21:54 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:22:02 [INFO] notebook - Data before 2018-06-21T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:22:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:22:12 [INFO] notebook - Data before 2018-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:22:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MMM/bars 3 more time(s)...\n",
      "2022-07-20 19:22:21 [INFO] notebook - Data before 2018-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:22:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:22:29 [INFO] notebook - Data before 2018-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:22:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:22:39 [INFO] notebook - Data before 2018-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:22:42 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:22:48 [INFO] notebook - Data before 2018-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:22:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:22:57 [INFO] notebook - Data before 2018-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:01 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:23:06 [INFO] notebook - Data before 2018-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:11 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:23:16 [INFO] notebook - Data before 2018-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:23:24 [INFO] notebook - Data before 2018-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:27 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MMM/bars 3 more time(s)...\n",
      "2022-07-20 19:23:33 [INFO] notebook - Data before 2018-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:37 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:23:42 [INFO] notebook - Data before 2018-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:46 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:23:51 [INFO] notebook - Data before 2018-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:23:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:24:00 [INFO] notebook - Data before 2018-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:24:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MMM/bars 3 more time(s)...\n",
      "2022-07-20 19:24:10 [INFO] notebook - Data before 2018-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:24:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:24:19 [INFO] notebook - Data before 2018-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:24:24 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:24:28 [INFO] notebook - Data before 2018-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:24:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:24:37 [INFO] notebook - Data before 2018-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:24:43 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:24:46 [INFO] notebook - Data before 2018-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:24:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DOW/bars 3 more time(s)...\n",
      "2022-07-20 19:24:55 [INFO] notebook - Data before 2018-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:02 [INFO] notebook - Data before 2018-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:25:11 [INFO] notebook - Data before 2018-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:13 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:25:21 [INFO] notebook - Data before 2018-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:23 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:25:29 [INFO] notebook - Data before 2018-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:25:38 [INFO] notebook - Data before 2018-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:40 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:25:47 [INFO] notebook - Data before 2018-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:25:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:25:57 [INFO] notebook - Data before 2018-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:04 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:26:07 [INFO] notebook - Data before 2018-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:13 [INFO] notebook - Data before 2018-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:14 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:26:23 [INFO] notebook - Data before 2018-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:24 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:26:32 [INFO] notebook - Data before 2018-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:33 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:26:41 [INFO] notebook - Data before 2018-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:43 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:26:51 [INFO] notebook - Data before 2018-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:26:53 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:27:00 [INFO] notebook - Data before 2018-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:27:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:27:10 [INFO] notebook - Data before 2018-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:27:16 [INFO] notebook - Data before 2018-07-26T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:27:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:27:26 [INFO] notebook - Data before 2018-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:27:27 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:27:35 [INFO] notebook - Data before 2018-07-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:27:36 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/GS/bars 3 more time(s)...\n",
      "2022-07-20 19:27:44 [INFO] notebook - Data before 2018-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:27:46 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:27:54 [INFO] notebook - Data before 2018-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:27:57 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:28:03 [INFO] notebook - Data before 2018-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:28:09 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:28:13 [INFO] notebook - Data before 2018-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:28:19 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:28:22 [INFO] notebook - Data before 2018-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:28:29 [INFO] notebook - Data before 2018-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:28:30 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:28:38 [INFO] notebook - Data before 2018-08-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:28:39 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:28:47 [INFO] notebook - Data before 2018-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:28:48 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:28:56 [INFO] notebook - Data before 2018-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:00 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:29:06 [INFO] notebook - Data before 2018-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:11 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:29:16 [INFO] notebook - Data before 2018-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:22 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:29:25 [INFO] notebook - Data before 2018-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:32 [INFO] notebook - Data before 2018-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n",
      "2022-07-20 19:29:41 [INFO] notebook - Data before 2018-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:43 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:29:51 [INFO] notebook - Data before 2018-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:29:53 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:30:00 [INFO] notebook - Data before 2018-08-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:30:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:30:10 [INFO] notebook - Data before 2018-08-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:30:17 [INFO] notebook - Data before 2018-08-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:30:18 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:30:27 [INFO] notebook - Data before 2018-08-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:30:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:30:37 [INFO] notebook - Data before 2018-08-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:30:42 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/VZ/bars 3 more time(s)...\n",
      "2022-07-20 19:30:46 [INFO] notebook - Data before 2018-08-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:30:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:30:55 [INFO] notebook - Data before 2018-08-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:31:06 [INFO] notebook - Data before 2018-08-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:31:17 [INFO] notebook - Data before 2018-08-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:31:30 [INFO] notebook - Data before 2018-08-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:31:45 [INFO] notebook - Data before 2018-08-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:31:58 [INFO] notebook - Data before 2018-08-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:04 [INFO] notebook - Data before 2018-08-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:11 [INFO] notebook - Data before 2018-08-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:19 [INFO] notebook - Data before 2018-08-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:26 [INFO] notebook - Data before 2018-08-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:33 [INFO] notebook - Data before 2018-08-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:40 [INFO] notebook - Data before 2018-08-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:47 [INFO] notebook - Data before 2018-08-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:32:53 [INFO] notebook - Data before 2018-09-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:00 [INFO] notebook - Data before 2018-09-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:33:09 [INFO] notebook - Data before 2018-09-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:33:19 [INFO] notebook - Data before 2018-09-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:26 [INFO] notebook - Data before 2018-09-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:30 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:33:37 [INFO] notebook - Data before 2018-09-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:43 [INFO] notebook - Data before 2018-09-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:33:53 [INFO] notebook - Data before 2018-09-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:33:55 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HD/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:34:03 [INFO] notebook - Data before 2018-09-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:34:07 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:34:13 [INFO] notebook - Data before 2018-09-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:34:20 [INFO] notebook - Data before 2018-09-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:34:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:34:30 [INFO] notebook - Data before 2018-09-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:34:36 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:34:40 [INFO] notebook - Data before 2018-09-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:34:47 [INFO] notebook - Data before 2018-09-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:34:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/HON/bars 3 more time(s)...\n",
      "2022-07-20 19:34:57 [INFO] notebook - Data before 2018-09-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:01 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/NKE/bars 3 more time(s)...\n",
      "2022-07-20 19:35:07 [INFO] notebook - Data before 2018-09-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:14 [INFO] notebook - Data before 2018-09-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:17 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:35:25 [INFO] notebook - Data before 2018-09-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:32 [INFO] notebook - Data before 2018-09-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:33 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:35:42 [INFO] notebook - Data before 2018-09-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:50 [INFO] notebook - Data before 2018-09-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:35:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:35:59 [INFO] notebook - Data before 2018-09-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:36:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:36:09 [INFO] notebook - Data before 2018-09-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:36:14 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:36:19 [INFO] notebook - Data before 2018-09-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:36:26 [INFO] notebook - Data before 2018-09-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:36:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MRK/bars 3 more time(s)...\n",
      "2022-07-20 19:36:37 [INFO] notebook - Data before 2018-09-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:36:44 [INFO] notebook - Data before 2018-09-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:36:49 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:36:55 [INFO] notebook - Data before 2018-09-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:01 [INFO] notebook - Data before 2018-09-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:37:11 [INFO] notebook - Data before 2018-09-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:15 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/JPM/bars 3 more time(s)...\n",
      "2022-07-20 19:37:22 [INFO] notebook - Data before 2018-10-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:29 [INFO] notebook - Data before 2018-10-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:33 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:37:40 [INFO] notebook - Data before 2018-10-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:47 [INFO] notebook - Data before 2018-10-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:37:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:37:58 [INFO] notebook - Data before 2018-10-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:05 [INFO] notebook - Data before 2018-10-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:08 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/INTC/bars 3 more time(s)...\n",
      "2022-07-20 19:38:19 [INFO] notebook - Data before 2018-10-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:27 [INFO] notebook - Data before 2018-10-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:34 [INFO] notebook - Data before 2018-10-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:41 [INFO] notebook - Data before 2018-10-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:47 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/UNH/bars 3 more time(s)...\n",
      "2022-07-20 19:38:52 [INFO] notebook - Data before 2018-10-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:38:59 [INFO] notebook - Data before 2018-10-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:02 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:39:09 [INFO] notebook - Data before 2018-10-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:16 [INFO] notebook - Data before 2018-10-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:16 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:39:27 [INFO] notebook - Data before 2018-10-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:34 [INFO] notebook - Data before 2018-10-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AXP/bars 3 more time(s)...\n",
      "2022-07-20 19:39:45 [INFO] notebook - Data before 2018-10-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:53 [INFO] notebook - Data before 2018-10-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:39:56 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/KO/bars 3 more time(s)...\n",
      "2022-07-20 19:40:04 [INFO] notebook - Data before 2018-10-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:40:11 [INFO] notebook - Data before 2018-10-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:40:12 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CVX/bars 3 more time(s)...\n",
      "2022-07-20 19:40:21 [INFO] notebook - Data before 2018-10-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:40:29 [INFO] notebook - Data before 2018-10-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:40:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:40:40 [INFO] notebook - Data before 2018-10-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:40:48 [INFO] notebook - Data before 2018-10-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:40:56 [INFO] notebook - Data before 2018-10-25T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:40:57 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CAT/bars 3 more time(s)...\n",
      "2022-07-20 19:41:06 [INFO] notebook - Data before 2018-10-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:41:14 [INFO] notebook - Data before 2018-10-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:41:14 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:41:24 [INFO] notebook - Data before 2018-10-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:41:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:41:34 [INFO] notebook - Data before 2018-10-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:41:42 [INFO] notebook - Data before 2018-10-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:41:50 [INFO] notebook - Data before 2018-10-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:41:56 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:42:01 [INFO] notebook - Data before 2018-11-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:42:09 [INFO] notebook - Data before 2018-11-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:42:16 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:42:20 [INFO] notebook - Data before 2018-11-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 19:42:27 [INFO] notebook - Data before 2018-11-04T14:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:42:35 [INFO] notebook - Data before 2018-11-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:42:44 [INFO] notebook - Data before 2018-11-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:42:44 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AAPL/bars 3 more time(s)...\n",
      "2022-07-20 19:42:55 [INFO] notebook - Data before 2018-11-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:03 [INFO] notebook - Data before 2018-11-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:10 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DOW/bars 3 more time(s)...\n",
      "2022-07-20 19:43:14 [INFO] notebook - Data before 2018-11-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:21 [INFO] notebook - Data before 2018-11-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:28 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:43:31 [INFO] notebook - Data before 2018-11-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:39 [INFO] notebook - Data before 2018-11-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:47 [INFO] notebook - Data before 2018-11-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:43:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:43:58 [INFO] notebook - Data before 2018-11-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:06 [INFO] notebook - Data before 2018-11-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:15 [INFO] notebook - Data before 2018-11-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:44:25 [INFO] notebook - Data before 2018-11-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:33 [INFO] notebook - Data before 2018-11-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:41 [INFO] notebook - Data before 2018-11-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:49 [INFO] notebook - Data before 2018-11-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:44:50 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/AMGN/bars 3 more time(s)...\n",
      "2022-07-20 19:45:01 [INFO] notebook - Data before 2018-11-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:45:08 [INFO] notebook - Data before 2018-11-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:45:14 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:45:19 [INFO] notebook - Data before 2018-11-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:45:27 [INFO] notebook - Data before 2018-11-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:45:34 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:45:37 [INFO] notebook - Data before 2018-11-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:45:46 [INFO] notebook - Data before 2018-11-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:45:54 [INFO] notebook - Data before 2018-11-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:02 [INFO] notebook - Data before 2018-11-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MCD/bars 3 more time(s)...\n",
      "2022-07-20 19:46:13 [INFO] notebook - Data before 2018-11-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:22 [INFO] notebook - Data before 2018-11-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:29 [INFO] notebook - Data before 2018-12-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:35 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/PG/bars 3 more time(s)...\n",
      "2022-07-20 19:46:40 [INFO] notebook - Data before 2018-12-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:49 [INFO] notebook - Data before 2018-12-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:46:57 [INFO] notebook - Data before 2018-12-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:47:07 [INFO] notebook - Data before 2018-12-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:16 [INFO] notebook - Data before 2018-12-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:24 [INFO] notebook - Data before 2018-12-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:31 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WMT/bars 3 more time(s)...\n",
      "2022-07-20 19:47:34 [INFO] notebook - Data before 2018-12-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:42 [INFO] notebook - Data before 2018-12-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:50 [INFO] notebook - Data before 2018-12-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:59 [INFO] notebook - Data before 2018-12-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:47:59 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/BA/bars 3 more time(s)...\n",
      "2022-07-20 19:48:10 [INFO] notebook - Data before 2018-12-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:48:18 [INFO] notebook - Data before 2018-12-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:48:26 [INFO] notebook - Data before 2018-12-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:48:32 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/TRV/bars 3 more time(s)...\n",
      "2022-07-20 19:48:37 [INFO] notebook - Data before 2018-12-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:48:45 [INFO] notebook - Data before 2018-12-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:48:53 [INFO] notebook - Data before 2018-12-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:49:02 [INFO] notebook - Data before 2018-12-18T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 19:49:03 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/CSCO/bars 3 more time(s)...\n",
      "2022-07-20 19:49:13 [INFO] notebook - Data before 2018-12-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:49:22 [INFO] notebook - Data before 2018-12-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:49:30 [INFO] notebook - Data before 2018-12-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:49:38 [INFO] notebook - Data before 2018-12-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:49:45 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/WBA/bars 3 more time(s)...\n",
      "2022-07-20 19:49:49 [INFO] notebook - Data before 2018-12-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:49:58 [INFO] notebook - Data before 2018-12-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:50:06 [INFO] notebook - Data before 2018-12-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:50:15 [INFO] notebook - Data before 2018-12-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:50:24 [INFO] notebook - Data before 2018-12-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:50:32 [INFO] notebook - Data before 2018-12-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:50:40 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/DIS/bars 3 more time(s)...\n",
      "2022-07-20 19:50:44 [INFO] notebook - Data before 2018-12-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:50:51 [INFO] notebook - Data before 2018-12-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:00 [INFO] notebook - Data before 2018-12-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:08 [INFO] notebook - Data before 2019-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:17 [INFO] notebook - Data before 2019-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:20 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/IBM/bars 3 more time(s)...\n",
      "2022-07-20 19:51:28 [INFO] notebook - Data before 2019-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:37 [INFO] notebook - Data before 2019-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:45 [INFO] notebook - Data before 2019-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:51:53 [INFO] notebook - Data before 2019-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:02 [INFO] notebook - Data before 2019-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:11 [INFO] notebook - Data before 2019-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:20 [INFO] notebook - Data before 2019-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:30 [INFO] notebook - Data before 2019-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:39 [INFO] notebook - Data before 2019-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:47 [INFO] notebook - Data before 2019-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:52:52 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/MSFT/bars 3 more time(s)...\n",
      "2022-07-20 19:52:58 [INFO] notebook - Data before 2019-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:07 [INFO] notebook - Data before 2019-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:16 [INFO] notebook - Data before 2019-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:25 [INFO] notebook - Data before 2019-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:34 [INFO] notebook - Data before 2019-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:42 [INFO] notebook - Data before 2019-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:51 [INFO] notebook - Data before 2019-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:53:59 [INFO] notebook - Data before 2019-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:54:06 [WARNING] alpaca_trade_api.rest - sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/V/bars 3 more time(s)...\n",
      "2022-07-20 19:54:11 [INFO] notebook - Data before 2019-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:54:19 [INFO] notebook - Data before 2019-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:54:28 [INFO] notebook - Data before 2019-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:54:38 [INFO] notebook - Data before 2019-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:54:47 [INFO] notebook - Data before 2019-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:54:55 [INFO] notebook - Data before 2019-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:03 [INFO] notebook - Data before 2019-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:12 [INFO] notebook - Data before 2019-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:21 [INFO] notebook - Data before 2019-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:30 [INFO] notebook - Data before 2019-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:39 [INFO] notebook - Data before 2019-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:48 [INFO] notebook - Data before 2019-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:55:57 [INFO] notebook - Data before 2019-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:56:07 [INFO] notebook - Data before 2019-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:56:17 [INFO] notebook - Data before 2019-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:56:26 [INFO] notebook - Data before 2019-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:56:35 [INFO] notebook - Data before 2019-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:56:45 [INFO] notebook - Data before 2019-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:56:54 [INFO] notebook - Data before 2019-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:02 [INFO] notebook - Data before 2019-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:11 [INFO] notebook - Data before 2019-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:20 [INFO] notebook - Data before 2019-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:30 [INFO] notebook - Data before 2019-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:39 [INFO] notebook - Data before 2019-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:49 [INFO] notebook - Data before 2019-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:57:59 [INFO] notebook - Data before 2019-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:58:08 [INFO] notebook - Data before 2019-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:58:17 [INFO] notebook - Data before 2019-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:58:26 [INFO] notebook - Data before 2019-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:58:35 [INFO] notebook - Data before 2019-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:58:44 [INFO] notebook - Data before 2019-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:58:54 [INFO] notebook - Data before 2019-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:03 [INFO] notebook - Data before 2019-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:12 [INFO] notebook - Data before 2019-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:21 [INFO] notebook - Data before 2019-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:30 [INFO] notebook - Data before 2019-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:40 [INFO] notebook - Data before 2019-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:50 [INFO] notebook - Data before 2019-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 19:59:59 [INFO] notebook - Data before 2019-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:00:08 [INFO] notebook - Data before 2019-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:00:18 [INFO] notebook - Data before 2019-03-02T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 20:00:27 [INFO] notebook - Data before 2019-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:00:37 [INFO] notebook - Data before 2019-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:00:47 [INFO] notebook - Data before 2019-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:00:56 [INFO] notebook - Data before 2019-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:01:06 [INFO] notebook - Data before 2019-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:01:16 [INFO] notebook - Data before 2019-03-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:01:25 [INFO] notebook - Data before 2019-03-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:01:34 [INFO] notebook - Data before 2019-03-10T16:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:01:44 [INFO] notebook - Data before 2019-03-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:01:54 [INFO] notebook - Data before 2019-03-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:02:04 [INFO] notebook - Data before 2019-03-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:02:15 [INFO] notebook - Data before 2019-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:02:24 [INFO] notebook - Data before 2019-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:02:35 [INFO] notebook - Data before 2019-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:02:44 [INFO] notebook - Data before 2019-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:02:54 [INFO] notebook - Data before 2019-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:03:04 [INFO] notebook - Data before 2019-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:03:14 [INFO] notebook - Data before 2019-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:03:24 [INFO] notebook - Data before 2019-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:03:35 [INFO] notebook - Data before 2019-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:03:43 [INFO] notebook - Data before 2019-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:03:53 [INFO] notebook - Data before 2019-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:04:04 [INFO] notebook - Data before 2019-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:04:14 [INFO] notebook - Data before 2019-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:04:24 [INFO] notebook - Data before 2019-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:04:34 [INFO] notebook - Data before 2019-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:04:45 [INFO] notebook - Data before 2019-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:04:55 [INFO] notebook - Data before 2019-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:05:04 [INFO] notebook - Data before 2019-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:05:14 [INFO] notebook - Data before 2019-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:05:24 [INFO] notebook - Data before 2019-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:05:35 [INFO] notebook - Data before 2019-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:05:45 [INFO] notebook - Data before 2019-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:05:55 [INFO] notebook - Data before 2019-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:06:05 [INFO] notebook - Data before 2019-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:06:14 [INFO] notebook - Data before 2019-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:06:25 [INFO] notebook - Data before 2019-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:06:34 [INFO] notebook - Data before 2019-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:06:45 [INFO] notebook - Data before 2019-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:06:55 [INFO] notebook - Data before 2019-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:07:06 [INFO] notebook - Data before 2019-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:07:15 [INFO] notebook - Data before 2019-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:07:25 [INFO] notebook - Data before 2019-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:07:35 [INFO] notebook - Data before 2019-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:07:46 [INFO] notebook - Data before 2019-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:07:56 [INFO] notebook - Data before 2019-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:08:07 [INFO] notebook - Data before 2019-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:08:16 [INFO] notebook - Data before 2019-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:08:26 [INFO] notebook - Data before 2019-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:08:36 [INFO] notebook - Data before 2019-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:08:46 [INFO] notebook - Data before 2019-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:08:56 [INFO] notebook - Data before 2019-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:09:06 [INFO] notebook - Data before 2019-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:09:17 [INFO] notebook - Data before 2019-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:09:27 [INFO] notebook - Data before 2019-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:09:37 [INFO] notebook - Data before 2019-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:09:47 [INFO] notebook - Data before 2019-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:09:57 [INFO] notebook - Data before 2019-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:10:07 [INFO] notebook - Data before 2019-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:10:17 [INFO] notebook - Data before 2019-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:10:27 [INFO] notebook - Data before 2019-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:10:37 [INFO] notebook - Data before 2019-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:10:47 [INFO] notebook - Data before 2019-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:10:57 [INFO] notebook - Data before 2019-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:11:07 [INFO] notebook - Data before 2019-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:11:17 [INFO] notebook - Data before 2019-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:11:28 [INFO] notebook - Data before 2019-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:11:38 [INFO] notebook - Data before 2019-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:11:48 [INFO] notebook - Data before 2019-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:11:58 [INFO] notebook - Data before 2019-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:12:08 [INFO] notebook - Data before 2019-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:12:18 [INFO] notebook - Data before 2019-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:12:28 [INFO] notebook - Data before 2019-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:12:39 [INFO] notebook - Data before 2019-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:12:49 [INFO] notebook - Data before 2019-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:13:00 [INFO] notebook - Data before 2019-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:13:10 [INFO] notebook - Data before 2019-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:13:19 [INFO] notebook - Data before 2019-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:13:30 [INFO] notebook - Data before 2019-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:13:47 [INFO] notebook - Data before 2019-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:14:10 [INFO] notebook - Data before 2019-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:14:33 [INFO] notebook - Data before 2019-05-23T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 20:14:44 [INFO] notebook - Data before 2019-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:14:54 [INFO] notebook - Data before 2019-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:15:04 [INFO] notebook - Data before 2019-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:15:14 [INFO] notebook - Data before 2019-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:15:25 [INFO] notebook - Data before 2019-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:15:35 [INFO] notebook - Data before 2019-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:15:46 [INFO] notebook - Data before 2019-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:15:57 [INFO] notebook - Data before 2019-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:16:07 [INFO] notebook - Data before 2019-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:16:17 [INFO] notebook - Data before 2019-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:16:28 [INFO] notebook - Data before 2019-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:16:39 [INFO] notebook - Data before 2019-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:16:50 [INFO] notebook - Data before 2019-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:17:00 [INFO] notebook - Data before 2019-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:17:12 [INFO] notebook - Data before 2019-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:17:21 [INFO] notebook - Data before 2019-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:17:31 [INFO] notebook - Data before 2019-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:17:43 [INFO] notebook - Data before 2019-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:17:53 [INFO] notebook - Data before 2019-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:18:04 [INFO] notebook - Data before 2019-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:18:15 [INFO] notebook - Data before 2019-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:18:26 [INFO] notebook - Data before 2019-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:18:37 [INFO] notebook - Data before 2019-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:18:47 [INFO] notebook - Data before 2019-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:18:58 [INFO] notebook - Data before 2019-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:19:09 [INFO] notebook - Data before 2019-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:19:20 [INFO] notebook - Data before 2019-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:19:31 [INFO] notebook - Data before 2019-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:19:43 [INFO] notebook - Data before 2019-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:19:53 [INFO] notebook - Data before 2019-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:20:04 [INFO] notebook - Data before 2019-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:20:16 [INFO] notebook - Data before 2019-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:20:26 [INFO] notebook - Data before 2019-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:20:37 [INFO] notebook - Data before 2019-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:20:49 [INFO] notebook - Data before 2019-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:20:59 [INFO] notebook - Data before 2019-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:21:10 [INFO] notebook - Data before 2019-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:21:20 [INFO] notebook - Data before 2019-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:21:32 [INFO] notebook - Data before 2019-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:21:42 [INFO] notebook - Data before 2019-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:21:53 [INFO] notebook - Data before 2019-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:22:04 [INFO] notebook - Data before 2019-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:22:15 [INFO] notebook - Data before 2019-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:22:26 [INFO] notebook - Data before 2019-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:22:37 [INFO] notebook - Data before 2019-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:22:48 [INFO] notebook - Data before 2019-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:23:00 [INFO] notebook - Data before 2019-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:23:11 [INFO] notebook - Data before 2019-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:23:22 [INFO] notebook - Data before 2019-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:23:33 [INFO] notebook - Data before 2019-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:23:44 [INFO] notebook - Data before 2019-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:23:55 [INFO] notebook - Data before 2019-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:24:07 [INFO] notebook - Data before 2019-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:24:19 [INFO] notebook - Data before 2019-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:24:30 [INFO] notebook - Data before 2019-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:24:44 [INFO] notebook - Data before 2019-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:24:56 [INFO] notebook - Data before 2019-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:25:07 [INFO] notebook - Data before 2019-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:25:18 [INFO] notebook - Data before 2019-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:25:29 [INFO] notebook - Data before 2019-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:25:41 [INFO] notebook - Data before 2019-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:25:54 [INFO] notebook - Data before 2019-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:26:05 [INFO] notebook - Data before 2019-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:26:17 [INFO] notebook - Data before 2019-07-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:26:29 [INFO] notebook - Data before 2019-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:26:40 [INFO] notebook - Data before 2019-07-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:26:51 [INFO] notebook - Data before 2019-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:27:04 [INFO] notebook - Data before 2019-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:27:15 [INFO] notebook - Data before 2019-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:27:27 [INFO] notebook - Data before 2019-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:27:38 [INFO] notebook - Data before 2019-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:27:49 [INFO] notebook - Data before 2019-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:28:00 [INFO] notebook - Data before 2019-08-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:28:12 [INFO] notebook - Data before 2019-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:28:23 [INFO] notebook - Data before 2019-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:28:35 [INFO] notebook - Data before 2019-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:28:46 [INFO] notebook - Data before 2019-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:28:58 [INFO] notebook - Data before 2019-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:29:09 [INFO] notebook - Data before 2019-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:29:20 [INFO] notebook - Data before 2019-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:29:32 [INFO] notebook - Data before 2019-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:29:43 [INFO] notebook - Data before 2019-08-13T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 20:29:55 [INFO] notebook - Data before 2019-08-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:30:07 [INFO] notebook - Data before 2019-08-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:30:19 [INFO] notebook - Data before 2019-08-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:30:30 [INFO] notebook - Data before 2019-08-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:30:41 [INFO] notebook - Data before 2019-08-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:30:54 [INFO] notebook - Data before 2019-08-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:31:05 [INFO] notebook - Data before 2019-08-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:31:17 [INFO] notebook - Data before 2019-08-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:31:29 [INFO] notebook - Data before 2019-08-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:31:41 [INFO] notebook - Data before 2019-08-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:31:52 [INFO] notebook - Data before 2019-08-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:32:03 [INFO] notebook - Data before 2019-08-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:32:16 [INFO] notebook - Data before 2019-08-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:32:28 [INFO] notebook - Data before 2019-08-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:32:40 [INFO] notebook - Data before 2019-08-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:32:52 [INFO] notebook - Data before 2019-08-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:33:04 [INFO] notebook - Data before 2019-08-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:33:15 [INFO] notebook - Data before 2019-08-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:33:26 [INFO] notebook - Data before 2019-09-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:33:38 [INFO] notebook - Data before 2019-09-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:33:50 [INFO] notebook - Data before 2019-09-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:34:02 [INFO] notebook - Data before 2019-09-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:34:14 [INFO] notebook - Data before 2019-09-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:34:26 [INFO] notebook - Data before 2019-09-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:34:37 [INFO] notebook - Data before 2019-09-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:34:49 [INFO] notebook - Data before 2019-09-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:35:01 [INFO] notebook - Data before 2019-09-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:35:13 [INFO] notebook - Data before 2019-09-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:35:25 [INFO] notebook - Data before 2019-09-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:35:38 [INFO] notebook - Data before 2019-09-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:35:50 [INFO] notebook - Data before 2019-09-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:36:01 [INFO] notebook - Data before 2019-09-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:36:14 [INFO] notebook - Data before 2019-09-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:36:27 [INFO] notebook - Data before 2019-09-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:36:40 [INFO] notebook - Data before 2019-09-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:36:52 [INFO] notebook - Data before 2019-09-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:37:04 [INFO] notebook - Data before 2019-09-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:37:16 [INFO] notebook - Data before 2019-09-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:37:28 [INFO] notebook - Data before 2019-09-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:37:40 [INFO] notebook - Data before 2019-09-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:37:52 [INFO] notebook - Data before 2019-09-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:38:05 [INFO] notebook - Data before 2019-09-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:38:18 [INFO] notebook - Data before 2019-09-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:38:30 [INFO] notebook - Data before 2019-09-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:38:42 [INFO] notebook - Data before 2019-09-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:38:54 [INFO] notebook - Data before 2019-09-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:39:05 [INFO] notebook - Data before 2019-09-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:39:17 [INFO] notebook - Data before 2019-09-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:39:29 [INFO] notebook - Data before 2019-10-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:39:43 [INFO] notebook - Data before 2019-10-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:39:55 [INFO] notebook - Data before 2019-10-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:40:06 [INFO] notebook - Data before 2019-10-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:40:19 [INFO] notebook - Data before 2019-10-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:40:31 [INFO] notebook - Data before 2019-10-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:40:42 [INFO] notebook - Data before 2019-10-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:40:59 [INFO] notebook - Data before 2019-10-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:41:13 [INFO] notebook - Data before 2019-10-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:41:27 [INFO] notebook - Data before 2019-10-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:41:42 [INFO] notebook - Data before 2019-10-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:41:56 [INFO] notebook - Data before 2019-10-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:42:08 [INFO] notebook - Data before 2019-10-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:42:21 [INFO] notebook - Data before 2019-10-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:42:34 [INFO] notebook - Data before 2019-10-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:42:47 [INFO] notebook - Data before 2019-10-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:42:59 [INFO] notebook - Data before 2019-10-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:43:12 [INFO] notebook - Data before 2019-10-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:43:24 [INFO] notebook - Data before 2019-10-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:43:36 [INFO] notebook - Data before 2019-10-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:43:49 [INFO] notebook - Data before 2019-10-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:44:01 [INFO] notebook - Data before 2019-10-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:44:14 [INFO] notebook - Data before 2019-10-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:44:27 [INFO] notebook - Data before 2019-10-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:44:40 [INFO] notebook - Data before 2019-10-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:44:52 [INFO] notebook - Data before 2019-10-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:45:04 [INFO] notebook - Data before 2019-10-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:45:17 [INFO] notebook - Data before 2019-10-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:45:29 [INFO] notebook - Data before 2019-10-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:45:42 [INFO] notebook - Data before 2019-10-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:45:54 [INFO] notebook - Data before 2019-10-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:46:07 [INFO] notebook - Data before 2019-11-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:46:19 [INFO] notebook - Data before 2019-11-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 20:46:31 [INFO] notebook - Data before 2019-11-03T14:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 20:46:44 [INFO] notebook - Data before 2019-11-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:46:57 [INFO] notebook - Data before 2019-11-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:47:09 [INFO] notebook - Data before 2019-11-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:47:22 [INFO] notebook - Data before 2019-11-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:47:35 [INFO] notebook - Data before 2019-11-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:47:47 [INFO] notebook - Data before 2019-11-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:47:59 [INFO] notebook - Data before 2019-11-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:48:12 [INFO] notebook - Data before 2019-11-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:48:25 [INFO] notebook - Data before 2019-11-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:48:37 [INFO] notebook - Data before 2019-11-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:48:50 [INFO] notebook - Data before 2019-11-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:49:02 [INFO] notebook - Data before 2019-11-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:49:15 [INFO] notebook - Data before 2019-11-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:49:27 [INFO] notebook - Data before 2019-11-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:49:40 [INFO] notebook - Data before 2019-11-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:49:53 [INFO] notebook - Data before 2019-11-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:50:06 [INFO] notebook - Data before 2019-11-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:50:20 [INFO] notebook - Data before 2019-11-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:50:33 [INFO] notebook - Data before 2019-11-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:50:46 [INFO] notebook - Data before 2019-11-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:50:58 [INFO] notebook - Data before 2019-11-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:51:12 [INFO] notebook - Data before 2019-11-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:51:25 [INFO] notebook - Data before 2019-11-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:51:39 [INFO] notebook - Data before 2019-11-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:51:52 [INFO] notebook - Data before 2019-11-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:52:05 [INFO] notebook - Data before 2019-11-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:52:17 [INFO] notebook - Data before 2019-11-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:52:30 [INFO] notebook - Data before 2019-12-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:52:43 [INFO] notebook - Data before 2019-12-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:52:57 [INFO] notebook - Data before 2019-12-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:53:10 [INFO] notebook - Data before 2019-12-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:53:23 [INFO] notebook - Data before 2019-12-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:53:36 [INFO] notebook - Data before 2019-12-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:53:49 [INFO] notebook - Data before 2019-12-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:54:02 [INFO] notebook - Data before 2019-12-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:54:15 [INFO] notebook - Data before 2019-12-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:54:28 [INFO] notebook - Data before 2019-12-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:54:43 [INFO] notebook - Data before 2019-12-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:54:56 [INFO] notebook - Data before 2019-12-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:55:10 [INFO] notebook - Data before 2019-12-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:55:26 [INFO] notebook - Data before 2019-12-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:55:40 [INFO] notebook - Data before 2019-12-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:55:54 [INFO] notebook - Data before 2019-12-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:56:07 [INFO] notebook - Data before 2019-12-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:56:21 [INFO] notebook - Data before 2019-12-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:56:35 [INFO] notebook - Data before 2019-12-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:56:51 [INFO] notebook - Data before 2019-12-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:57:07 [INFO] notebook - Data before 2019-12-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:57:21 [INFO] notebook - Data before 2019-12-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:57:34 [INFO] notebook - Data before 2019-12-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:57:48 [INFO] notebook - Data before 2019-12-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:58:00 [INFO] notebook - Data before 2019-12-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:58:14 [INFO] notebook - Data before 2019-12-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:58:28 [INFO] notebook - Data before 2019-12-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:58:41 [INFO] notebook - Data before 2019-12-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:58:54 [INFO] notebook - Data before 2019-12-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:59:07 [INFO] notebook - Data before 2019-12-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:59:21 [INFO] notebook - Data before 2019-12-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:59:34 [INFO] notebook - Data before 2020-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 20:59:47 [INFO] notebook - Data before 2020-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:00:01 [INFO] notebook - Data before 2020-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:00:14 [INFO] notebook - Data before 2020-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:00:27 [INFO] notebook - Data before 2020-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:00:41 [INFO] notebook - Data before 2020-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:00:54 [INFO] notebook - Data before 2020-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:01:08 [INFO] notebook - Data before 2020-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:01:21 [INFO] notebook - Data before 2020-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:01:35 [INFO] notebook - Data before 2020-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:01:49 [INFO] notebook - Data before 2020-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:02:01 [INFO] notebook - Data before 2020-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:02:15 [INFO] notebook - Data before 2020-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:02:30 [INFO] notebook - Data before 2020-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:02:43 [INFO] notebook - Data before 2020-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:02:59 [INFO] notebook - Data before 2020-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:03:12 [INFO] notebook - Data before 2020-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:03:25 [INFO] notebook - Data before 2020-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:03:38 [INFO] notebook - Data before 2020-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:03:51 [INFO] notebook - Data before 2020-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:04:05 [INFO] notebook - Data before 2020-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:04:19 [INFO] notebook - Data before 2020-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:04:34 [INFO] notebook - Data before 2020-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:04:47 [INFO] notebook - Data before 2020-01-24T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 21:05:01 [INFO] notebook - Data before 2020-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:05:32 [INFO] notebook - Data before 2020-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:06:35 [INFO] notebook - Data before 2020-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:07:02 [INFO] notebook - Data before 2020-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:07:16 [INFO] notebook - Data before 2020-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:07:31 [INFO] notebook - Data before 2020-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:07:45 [INFO] notebook - Data before 2020-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:07:58 [INFO] notebook - Data before 2020-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:08:12 [INFO] notebook - Data before 2020-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:08:27 [INFO] notebook - Data before 2020-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:08:41 [INFO] notebook - Data before 2020-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:08:56 [INFO] notebook - Data before 2020-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:09:10 [INFO] notebook - Data before 2020-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:09:24 [INFO] notebook - Data before 2020-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:09:37 [INFO] notebook - Data before 2020-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:09:51 [INFO] notebook - Data before 2020-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:10:05 [INFO] notebook - Data before 2020-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:10:20 [INFO] notebook - Data before 2020-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:10:34 [INFO] notebook - Data before 2020-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:10:50 [INFO] notebook - Data before 2020-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:11:04 [INFO] notebook - Data before 2020-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:11:18 [INFO] notebook - Data before 2020-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:11:32 [INFO] notebook - Data before 2020-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:11:45 [INFO] notebook - Data before 2020-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:12:00 [INFO] notebook - Data before 2020-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:12:14 [INFO] notebook - Data before 2020-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:12:28 [INFO] notebook - Data before 2020-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:13:42 [INFO] notebook - Data before 2020-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:15:55 [INFO] notebook - Data before 2020-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:17:16 [INFO] notebook - Data before 2020-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:17:46 [INFO] notebook - Data before 2020-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:18:01 [INFO] notebook - Data before 2020-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:18:16 [INFO] notebook - Data before 2020-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:18:30 [INFO] notebook - Data before 2020-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:18:44 [INFO] notebook - Data before 2020-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:18:58 [INFO] notebook - Data before 2020-02-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:19:12 [INFO] notebook - Data before 2020-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:19:26 [INFO] notebook - Data before 2020-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:19:41 [INFO] notebook - Data before 2020-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:19:55 [INFO] notebook - Data before 2020-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:20:09 [INFO] notebook - Data before 2020-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:20:25 [INFO] notebook - Data before 2020-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:20:39 [INFO] notebook - Data before 2020-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 21:20:53 [INFO] notebook - Data before 2020-03-08T16:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:21:07 [INFO] notebook - Data before 2020-03-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:21:22 [INFO] notebook - Data before 2020-03-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:21:37 [INFO] notebook - Data before 2020-03-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:21:51 [INFO] notebook - Data before 2020-03-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:22:06 [INFO] notebook - Data before 2020-03-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:22:21 [INFO] notebook - Data before 2020-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:22:35 [INFO] notebook - Data before 2020-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:22:50 [INFO] notebook - Data before 2020-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:23:06 [INFO] notebook - Data before 2020-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:23:21 [INFO] notebook - Data before 2020-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:23:36 [INFO] notebook - Data before 2020-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:23:51 [INFO] notebook - Data before 2020-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:24:05 [INFO] notebook - Data before 2020-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:24:19 [INFO] notebook - Data before 2020-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:24:35 [INFO] notebook - Data before 2020-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:24:50 [INFO] notebook - Data before 2020-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:25:05 [INFO] notebook - Data before 2020-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:25:20 [INFO] notebook - Data before 2020-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:25:35 [INFO] notebook - Data before 2020-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:25:49 [INFO] notebook - Data before 2020-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:26:03 [INFO] notebook - Data before 2020-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:26:19 [INFO] notebook - Data before 2020-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:26:33 [INFO] notebook - Data before 2020-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:26:48 [INFO] notebook - Data before 2020-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:27:03 [INFO] notebook - Data before 2020-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:27:18 [INFO] notebook - Data before 2020-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:27:33 [INFO] notebook - Data before 2020-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:27:48 [INFO] notebook - Data before 2020-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:28:03 [INFO] notebook - Data before 2020-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:28:18 [INFO] notebook - Data before 2020-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:28:32 [INFO] notebook - Data before 2020-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:28:48 [INFO] notebook - Data before 2020-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:29:02 [INFO] notebook - Data before 2020-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:29:16 [INFO] notebook - Data before 2020-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:29:32 [INFO] notebook - Data before 2020-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:29:50 [INFO] notebook - Data before 2020-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:30:05 [INFO] notebook - Data before 2020-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:30:20 [INFO] notebook - Data before 2020-04-15T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 21:30:35 [INFO] notebook - Data before 2020-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:30:51 [INFO] notebook - Data before 2020-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:31:05 [INFO] notebook - Data before 2020-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:31:19 [INFO] notebook - Data before 2020-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:31:35 [INFO] notebook - Data before 2020-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:31:49 [INFO] notebook - Data before 2020-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:32:05 [INFO] notebook - Data before 2020-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:32:20 [INFO] notebook - Data before 2020-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:32:35 [INFO] notebook - Data before 2020-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:32:52 [INFO] notebook - Data before 2020-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:33:08 [INFO] notebook - Data before 2020-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:33:23 [INFO] notebook - Data before 2020-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:33:39 [INFO] notebook - Data before 2020-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:33:55 [INFO] notebook - Data before 2020-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:34:10 [INFO] notebook - Data before 2020-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:34:25 [INFO] notebook - Data before 2020-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:34:40 [INFO] notebook - Data before 2020-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:34:55 [INFO] notebook - Data before 2020-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:35:10 [INFO] notebook - Data before 2020-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:35:25 [INFO] notebook - Data before 2020-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:35:40 [INFO] notebook - Data before 2020-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:35:56 [INFO] notebook - Data before 2020-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:36:12 [INFO] notebook - Data before 2020-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:36:27 [INFO] notebook - Data before 2020-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:36:42 [INFO] notebook - Data before 2020-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:36:57 [INFO] notebook - Data before 2020-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:37:13 [INFO] notebook - Data before 2020-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:37:32 [INFO] notebook - Data before 2020-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:37:50 [INFO] notebook - Data before 2020-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:38:06 [INFO] notebook - Data before 2020-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:38:21 [INFO] notebook - Data before 2020-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:38:35 [INFO] notebook - Data before 2020-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:38:51 [INFO] notebook - Data before 2020-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:39:06 [INFO] notebook - Data before 2020-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:39:22 [INFO] notebook - Data before 2020-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:39:38 [INFO] notebook - Data before 2020-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:39:55 [INFO] notebook - Data before 2020-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:40:11 [INFO] notebook - Data before 2020-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:40:28 [INFO] notebook - Data before 2020-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:40:45 [INFO] notebook - Data before 2020-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:41:01 [INFO] notebook - Data before 2020-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:41:17 [INFO] notebook - Data before 2020-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:41:33 [INFO] notebook - Data before 2020-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:41:49 [INFO] notebook - Data before 2020-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:42:04 [INFO] notebook - Data before 2020-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:42:19 [INFO] notebook - Data before 2020-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:42:35 [INFO] notebook - Data before 2020-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:42:50 [INFO] notebook - Data before 2020-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:43:07 [INFO] notebook - Data before 2020-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:43:22 [INFO] notebook - Data before 2020-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:43:38 [INFO] notebook - Data before 2020-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:43:53 [INFO] notebook - Data before 2020-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:44:08 [INFO] notebook - Data before 2020-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:44:24 [INFO] notebook - Data before 2020-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:44:39 [INFO] notebook - Data before 2020-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:44:55 [INFO] notebook - Data before 2020-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:45:11 [INFO] notebook - Data before 2020-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:45:27 [INFO] notebook - Data before 2020-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:45:42 [INFO] notebook - Data before 2020-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:45:57 [INFO] notebook - Data before 2020-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:46:13 [INFO] notebook - Data before 2020-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:46:29 [INFO] notebook - Data before 2020-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:46:45 [INFO] notebook - Data before 2020-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:47:01 [INFO] notebook - Data before 2020-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:47:17 [INFO] notebook - Data before 2020-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:47:32 [INFO] notebook - Data before 2020-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:47:47 [INFO] notebook - Data before 2020-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:48:04 [INFO] notebook - Data before 2020-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:48:19 [INFO] notebook - Data before 2020-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:48:36 [INFO] notebook - Data before 2020-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:48:51 [INFO] notebook - Data before 2020-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:49:07 [INFO] notebook - Data before 2020-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:49:23 [INFO] notebook - Data before 2020-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:49:38 [INFO] notebook - Data before 2020-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:49:54 [INFO] notebook - Data before 2020-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:50:10 [INFO] notebook - Data before 2020-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:50:26 [INFO] notebook - Data before 2020-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:50:43 [INFO] notebook - Data before 2020-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:50:58 [INFO] notebook - Data before 2020-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:51:14 [INFO] notebook - Data before 2020-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:51:30 [INFO] notebook - Data before 2020-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:51:46 [INFO] notebook - Data before 2020-07-06T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 21:52:03 [INFO] notebook - Data before 2020-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:52:19 [INFO] notebook - Data before 2020-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:52:35 [INFO] notebook - Data before 2020-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:52:52 [INFO] notebook - Data before 2020-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:53:10 [INFO] notebook - Data before 2020-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:53:25 [INFO] notebook - Data before 2020-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:53:42 [INFO] notebook - Data before 2020-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:53:58 [INFO] notebook - Data before 2020-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:54:14 [INFO] notebook - Data before 2020-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:54:30 [INFO] notebook - Data before 2020-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:54:46 [INFO] notebook - Data before 2020-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:55:01 [INFO] notebook - Data before 2020-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:55:17 [INFO] notebook - Data before 2020-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:55:33 [INFO] notebook - Data before 2020-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:55:50 [INFO] notebook - Data before 2020-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:56:06 [INFO] notebook - Data before 2020-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:56:22 [INFO] notebook - Data before 2020-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:56:38 [INFO] notebook - Data before 2020-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:56:54 [INFO] notebook - Data before 2020-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:57:09 [INFO] notebook - Data before 2020-07-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:57:26 [INFO] notebook - Data before 2020-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:57:44 [INFO] notebook - Data before 2020-07-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:58:00 [INFO] notebook - Data before 2020-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:58:16 [INFO] notebook - Data before 2020-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:58:32 [INFO] notebook - Data before 2020-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:58:48 [INFO] notebook - Data before 2020-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:59:03 [INFO] notebook - Data before 2020-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:59:20 [INFO] notebook - Data before 2020-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:59:37 [INFO] notebook - Data before 2020-08-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 21:59:53 [INFO] notebook - Data before 2020-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:00:09 [INFO] notebook - Data before 2020-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:00:26 [INFO] notebook - Data before 2020-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:00:42 [INFO] notebook - Data before 2020-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:00:57 [INFO] notebook - Data before 2020-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:01:14 [INFO] notebook - Data before 2020-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:01:31 [INFO] notebook - Data before 2020-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:01:48 [INFO] notebook - Data before 2020-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:02:04 [INFO] notebook - Data before 2020-08-13T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionAbortedError(10053, 'An established connection was aborted by the software in your host machine', None, 10053, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionAbortedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mConnectionAbortedError\u001b[0m: [WinError 10053] An established connection was aborted by the software in your host machine",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\packages\\six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionAbortedError(10053, 'An established connection was aborted by the software in your host machine', None, 10053, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mDP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2018-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022-07-20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcandle_time_interval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\code\\forex\\finrl\\finrl\\finrl_meta\\data_processor.py:36\u001b[0m, in \u001b[0;36mDataProcessor.download_data\u001b[1;34m(self, ticker_list, start_date, end_date, time_interval, dataset_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_data\u001b[39m(\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m, ticker_list, start_date, end_date, time_interval, dataset_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m---> 36\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticker_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mticker_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\code\\forex\\finrl\\finrl\\finrl_meta\\data_processors\\processor_alpaca.py:60\u001b[0m, in \u001b[0;36mAlpacaProcessor.download_data\u001b[1;34m(self, ticker_list, start_date, end_date, time_interval, dataset_path)\u001b[0m\n\u001b[0;32m     58\u001b[0m     barset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_feather(feather_file_path, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     barset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bars\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdf\n\u001b[0;32m     63\u001b[0m     barset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tic\n\u001b[0;32m     64\u001b[0m     barset \u001b[38;5;241m=\u001b[39m barset\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\alpaca_trade_api\\rest.py:714\u001b[0m, in \u001b[0;36mREST.get_bars\u001b[1;34m(self, symbol, timeframe, start, end, adjustment, limit, feed, asof)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bars\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    705\u001b[0m              symbol: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m    706\u001b[0m              timeframe: TimeFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    712\u001b[0m              asof: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    713\u001b[0m              ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarsV2:\n\u001b[1;32m--> 714\u001b[0m     bars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bars_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madjustment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mfeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43masof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BarsV2(bars)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\alpaca_trade_api\\rest.py:698\u001b[0m, in \u001b[0;36mREST.get_bars_iter\u001b[1;34m(self, symbol, timeframe, start, end, adjustment, limit, feed, asof, raw)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bars_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    681\u001b[0m                   symbol: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m    682\u001b[0m                   timeframe: TimeFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    688\u001b[0m                   asof: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    689\u001b[0m                   raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarIterator:\n\u001b[0;32m    690\u001b[0m     bars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_get(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbars\u001b[39m\u001b[38;5;124m'\u001b[39m, symbol,\n\u001b[0;32m    691\u001b[0m                           timeframe\u001b[38;5;241m=\u001b[39mtimeframe,\n\u001b[0;32m    692\u001b[0m                           adjustment\u001b[38;5;241m=\u001b[39madjustment,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    696\u001b[0m                           feed\u001b[38;5;241m=\u001b[39mfeed,\n\u001b[0;32m    697\u001b[0m                           asof\u001b[38;5;241m=\u001b[39masof)\n\u001b[1;32m--> 698\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bar \u001b[38;5;129;01min\u001b[39;00m bars:\n\u001b[0;32m    699\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m raw:\n\u001b[0;32m    700\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m bar\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\alpaca_trade_api\\rest.py:585\u001b[0m, in \u001b[0;36mREST._data_get\u001b[1;34m(self, endpoint, symbol_or_symbols, api_version, endpoint_base, resp_grouped_by_symbol, page_limit, feed, asof, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endpoint:\n\u001b[0;32m    584\u001b[0m     path \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 585\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resp_grouped_by_symbol:\n\u001b[0;32m    588\u001b[0m     k \u001b[38;5;241m=\u001b[39m endpoint \u001b[38;5;129;01mor\u001b[39;00m endpoint_base\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\alpaca_trade_api\\rest.py:270\u001b[0m, in \u001b[0;36mREST.data_get\u001b[1;34m(self, path, data, feed, api_version)\u001b[0m\n\u001b[0;32m    268\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    269\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m feed\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\alpaca_trade_api\\rest.py:213\u001b[0m, in \u001b[0;36mREST._request\u001b[1;34m(self, method, path, data, base_url, api_version)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RetryException:\n\u001b[0;32m    215\u001b[0m         retry_wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_wait\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\alpaca_trade_api\\rest.py:232\u001b[0m, in \u001b[0;36mREST._one_request\u001b[1;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03mPerform one request, possibly raising RetryException in the case\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03mthe response is 429. Otherwise, if error text contain \"code\" string,\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03mthen it decodes to json object and returns APIError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03mReturns the body json in the 200 status.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m retry_codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_codes\n\u001b[1;32m--> 232\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\requests\\adapters.py:547\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionAbortedError(10053, 'An established connection was aborted by the software in your host machine', None, 10053, None))"
     ]
    }
   ],
   "source": [
    "data = DP.download_data(start_date = '2018-01-01', \n",
    "                        end_date = '2022-07-20',\n",
    "                        ticker_list = ticker_list, \n",
    "                        time_interval= candle_time_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i46jGdE0IAel"
   },
   "source": [
    "### Step 3. Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9euUsEPHWFK",
    "outputId": "e513d0d7-43ef-40b4-b0b5-b329bdfb0d1a"
   },
   "outputs": [],
   "source": [
    "data = DP.clean_data(data)\n",
    "data = DP.add_technical_indicator(data, INDICATORS)\n",
    "data = DP.add_vix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GOcPTaAgHdxa",
    "outputId": "0ec040ba-a7cf-48d0-c7a9-f11770da68f1"
   },
   "outputs": [],
   "source": [
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbu03L_UIMWt"
   },
   "source": [
    "### Step 4. Transform to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rzj0vjZZHdGM",
    "outputId": "c6e08f9e-034b-4161-f8f3-2e61426a78c0"
   },
   "outputs": [],
   "source": [
    "price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "778F_9aVJPNq",
    "outputId": "cdb23360-53da-48f1-c4d2-815297d3b4b1"
   },
   "outputs": [],
   "source": [
    "price_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW0UDAXI1nEa"
   },
   "source": [
    "# Part 2: Train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lArLOFcJ7VMO"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g1F84mebj4gu"
   },
   "outputs": [],
   "source": [
    "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n",
    "        \"seed\":312,\"net_dimension\":512, \"target_step\":5000, \"eval_gap\":30,\n",
    "        \"eval_times\":1} \n",
    "#if you want to use larger datasets (change to longer period), and it raises error, \n",
    "#please try to increase \"target_step\". It should be larger than the episode steps. \n",
    "\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "TRAIN_START_DATE = '2018-01-01'\n",
    "TRAIN_END_DATE = '2022-07-20'\n",
    "MODEL_NAME = 'ppo'\n",
    "TOTAL_TIMESTEPS = 1e6\n",
    "VERSION= datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "TRAIN_CWD = f'./models/papertrading/{MODEL_NAME}_train_{TOTAL_TIMESTEPS}_{TRAIN_START_DATE}_{TRAIN_END_DATE}_{candle_time_interval}_{VERSION}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxcNI2fdNjip",
    "outputId": "5f638ed6-7dbf-4771-a0cc-3617d5e9b875",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train(start_date = TRAIN_START_DATE, \n",
    "      end_date = TRAIN_END_DATE,\n",
    "      ticker_list = ticker_list, \n",
    "      data_source = 'alpaca',\n",
    "      time_interval= candle_time_interval, \n",
    "      technical_indicator_list= INDICATORS,\n",
    "      drl_lib='stable_baselines3', \n",
    "      env=env,\n",
    "      model_name = MODEL_NAME, \n",
    "      API_KEY = API_KEY, \n",
    "      API_SECRET = API_SECRET, \n",
    "      API_BASE_URL = API_BASE_URL,\n",
    "      agent_params=PPO_PARAMS,\n",
    "      total_timesteps=TOTAL_TIMESTEPS,\n",
    "      cwd=TRAIN_CWD, #current_working_dir\n",
    "      break_step=1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g37WugV_1pAS"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_START_DATE = '2022-07-11'\n",
    "TEST_END_DATE = '2022-07-19'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxYoWCDa02TW",
    "outputId": "b542ce55-2479-4168-fb2a-79f0a3da12c3"
   },
   "outputs": [],
   "source": [
    "CWD = './models/papertrading/ppo_retrain_1000000.0_2022-01-03_2022-07-18_15Min_1.0.0'\n",
    "account_value_erl=test(start_date = TEST_START_DATE, \n",
    "                      end_date = TEST_END_DATE,\n",
    "                      ticker_list = ticker_list, \n",
    "                      data_source = 'alpaca',\n",
    "                      time_interval= candle_time_interval, \n",
    "                      technical_indicator_list= INDICATORS,\n",
    "                      drl_lib='stable_baselines3', \n",
    "                      env=env, \n",
    "                      model_name=MODEL_NAME, \n",
    "                      API_KEY = API_KEY, \n",
    "                      API_SECRET = API_SECRET, \n",
    "                      API_BASE_URL = API_BASE_URL,\n",
    "                      cwd=CWD,\n",
    "                      net_dimension = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8aNQ58X7avM"
   },
   "source": [
    "## Use full data totrain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CQ9_Yv41r88"
   },
   "source": [
    "After tuning well, retrain on the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRAIN_START_DATE = '2018-01-01'\n",
    "RETRAIN_END_DATE = '2022-07-20'\n",
    "RETRAIN_CWD = f'./models/papertrading/{MODEL_NAME}_retrain_{TOTAL_TIMESTEPS}_{TRAIN_START_DATE}_{TRAIN_END_DATE}_{candle_time_interval}_{VERSION}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUSgbwt_10V3",
    "outputId": "e7669aa1-b5d2-48b5-8aee-509a2822b7b4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca successfully connected\n",
      "2022-07-20 22:50:54 [INFO] notebook - Data before 2018-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:54 [INFO] notebook - Data before 2018-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:54 [INFO] notebook - Data before 2018-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:54 [INFO] notebook - Data before 2018-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:55 [INFO] notebook - Data before 2018-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:55 [INFO] notebook - Data before 2018-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:55 [INFO] notebook - Data before 2018-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:55 [INFO] notebook - Data before 2018-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:55 [INFO] notebook - Data before 2018-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:56 [INFO] notebook - Data before 2018-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:56 [INFO] notebook - Data before 2018-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:56 [INFO] notebook - Data before 2018-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:57 [INFO] notebook - Data before 2018-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:57 [INFO] notebook - Data before 2018-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:57 [INFO] notebook - Data before 2018-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:57 [INFO] notebook - Data before 2018-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:58 [INFO] notebook - Data before 2018-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:58 [INFO] notebook - Data before 2018-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:58 [INFO] notebook - Data before 2018-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:59 [INFO] notebook - Data before 2018-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:59 [INFO] notebook - Data before 2018-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:50:59 [INFO] notebook - Data before 2018-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:00 [INFO] notebook - Data before 2018-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:00 [INFO] notebook - Data before 2018-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:01 [INFO] notebook - Data before 2018-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:01 [INFO] notebook - Data before 2018-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:02 [INFO] notebook - Data before 2018-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:02 [INFO] notebook - Data before 2018-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:03 [INFO] notebook - Data before 2018-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:03 [INFO] notebook - Data before 2018-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:04 [INFO] notebook - Data before 2018-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:04 [INFO] notebook - Data before 2018-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:05 [INFO] notebook - Data before 2018-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:05 [INFO] notebook - Data before 2018-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:06 [INFO] notebook - Data before 2018-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:08 [INFO] notebook - Data before 2018-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:08 [INFO] notebook - Data before 2018-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:09 [INFO] notebook - Data before 2018-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:10 [INFO] notebook - Data before 2018-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:10 [INFO] notebook - Data before 2018-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:11 [INFO] notebook - Data before 2018-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:12 [INFO] notebook - Data before 2018-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:12 [INFO] notebook - Data before 2018-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:13 [INFO] notebook - Data before 2018-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:14 [INFO] notebook - Data before 2018-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:15 [INFO] notebook - Data before 2018-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:15 [INFO] notebook - Data before 2018-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:16 [INFO] notebook - Data before 2018-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:17 [INFO] notebook - Data before 2018-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:17 [INFO] notebook - Data before 2018-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:18 [INFO] notebook - Data before 2018-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:19 [INFO] notebook - Data before 2018-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:20 [INFO] notebook - Data before 2018-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:21 [INFO] notebook - Data before 2018-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:21 [INFO] notebook - Data before 2018-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:22 [INFO] notebook - Data before 2018-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:23 [INFO] notebook - Data before 2018-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:24 [INFO] notebook - Data before 2018-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:25 [INFO] notebook - Data before 2018-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:26 [INFO] notebook - Data before 2018-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:26 [INFO] notebook - Data before 2018-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:27 [INFO] notebook - Data before 2018-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:28 [INFO] notebook - Data before 2018-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:29 [INFO] notebook - Data before 2018-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:30 [INFO] notebook - Data before 2018-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:31 [INFO] notebook - Data before 2018-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:32 [INFO] notebook - Data before 2018-03-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:33 [INFO] notebook - Data before 2018-03-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:34 [INFO] notebook - Data before 2018-03-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 22:51:35 [INFO] notebook - Data before 2018-03-11T16:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:36 [INFO] notebook - Data before 2018-03-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:37 [INFO] notebook - Data before 2018-03-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:38 [INFO] notebook - Data before 2018-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:39 [INFO] notebook - Data before 2018-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:40 [INFO] notebook - Data before 2018-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:41 [INFO] notebook - Data before 2018-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:42 [INFO] notebook - Data before 2018-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:44 [INFO] notebook - Data before 2018-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:45 [INFO] notebook - Data before 2018-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:46 [INFO] notebook - Data before 2018-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:47 [INFO] notebook - Data before 2018-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:48 [INFO] notebook - Data before 2018-03-23T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 22:51:49 [INFO] notebook - Data before 2018-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:51 [INFO] notebook - Data before 2018-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:52 [INFO] notebook - Data before 2018-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:53 [INFO] notebook - Data before 2018-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:54 [INFO] notebook - Data before 2018-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:55 [INFO] notebook - Data before 2018-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:57 [INFO] notebook - Data before 2018-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:58 [INFO] notebook - Data before 2018-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:51:59 [INFO] notebook - Data before 2018-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:00 [INFO] notebook - Data before 2018-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:02 [INFO] notebook - Data before 2018-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:03 [INFO] notebook - Data before 2018-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:04 [INFO] notebook - Data before 2018-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:06 [INFO] notebook - Data before 2018-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:07 [INFO] notebook - Data before 2018-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:08 [INFO] notebook - Data before 2018-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:10 [INFO] notebook - Data before 2018-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:11 [INFO] notebook - Data before 2018-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:12 [INFO] notebook - Data before 2018-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:14 [INFO] notebook - Data before 2018-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:15 [INFO] notebook - Data before 2018-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:17 [INFO] notebook - Data before 2018-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:19 [INFO] notebook - Data before 2018-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:20 [INFO] notebook - Data before 2018-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:22 [INFO] notebook - Data before 2018-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:23 [INFO] notebook - Data before 2018-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:25 [INFO] notebook - Data before 2018-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:26 [INFO] notebook - Data before 2018-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:28 [INFO] notebook - Data before 2018-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:29 [INFO] notebook - Data before 2018-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:31 [INFO] notebook - Data before 2018-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:32 [INFO] notebook - Data before 2018-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:34 [INFO] notebook - Data before 2018-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:36 [INFO] notebook - Data before 2018-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:37 [INFO] notebook - Data before 2018-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:39 [INFO] notebook - Data before 2018-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:41 [INFO] notebook - Data before 2018-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:42 [INFO] notebook - Data before 2018-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:44 [INFO] notebook - Data before 2018-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:46 [INFO] notebook - Data before 2018-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:47 [INFO] notebook - Data before 2018-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:49 [INFO] notebook - Data before 2018-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:51 [INFO] notebook - Data before 2018-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:53 [INFO] notebook - Data before 2018-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:54 [INFO] notebook - Data before 2018-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:56 [INFO] notebook - Data before 2018-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:52:58 [INFO] notebook - Data before 2018-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:00 [INFO] notebook - Data before 2018-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:02 [INFO] notebook - Data before 2018-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:03 [INFO] notebook - Data before 2018-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:05 [INFO] notebook - Data before 2018-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:07 [INFO] notebook - Data before 2018-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:09 [INFO] notebook - Data before 2018-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:11 [INFO] notebook - Data before 2018-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:13 [INFO] notebook - Data before 2018-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:15 [INFO] notebook - Data before 2018-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:16 [INFO] notebook - Data before 2018-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:18 [INFO] notebook - Data before 2018-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:20 [INFO] notebook - Data before 2018-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:22 [INFO] notebook - Data before 2018-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:24 [INFO] notebook - Data before 2018-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:26 [INFO] notebook - Data before 2018-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:28 [INFO] notebook - Data before 2018-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:30 [INFO] notebook - Data before 2018-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:32 [INFO] notebook - Data before 2018-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:34 [INFO] notebook - Data before 2018-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:37 [INFO] notebook - Data before 2018-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:39 [INFO] notebook - Data before 2018-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:41 [INFO] notebook - Data before 2018-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:43 [INFO] notebook - Data before 2018-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:45 [INFO] notebook - Data before 2018-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:47 [INFO] notebook - Data before 2018-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:49 [INFO] notebook - Data before 2018-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:51 [INFO] notebook - Data before 2018-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:53 [INFO] notebook - Data before 2018-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:56 [INFO] notebook - Data before 2018-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:53:58 [INFO] notebook - Data before 2018-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:00 [INFO] notebook - Data before 2018-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:02 [INFO] notebook - Data before 2018-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:04 [INFO] notebook - Data before 2018-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:07 [INFO] notebook - Data before 2018-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:09 [INFO] notebook - Data before 2018-06-13T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 22:54:11 [INFO] notebook - Data before 2018-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:13 [INFO] notebook - Data before 2018-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:16 [INFO] notebook - Data before 2018-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:18 [INFO] notebook - Data before 2018-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:20 [INFO] notebook - Data before 2018-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:23 [INFO] notebook - Data before 2018-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:25 [INFO] notebook - Data before 2018-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:28 [INFO] notebook - Data before 2018-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:30 [INFO] notebook - Data before 2018-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:32 [INFO] notebook - Data before 2018-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:35 [INFO] notebook - Data before 2018-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:37 [INFO] notebook - Data before 2018-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:40 [INFO] notebook - Data before 2018-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:42 [INFO] notebook - Data before 2018-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:45 [INFO] notebook - Data before 2018-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:47 [INFO] notebook - Data before 2018-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:49 [INFO] notebook - Data before 2018-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:52 [INFO] notebook - Data before 2018-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:54 [INFO] notebook - Data before 2018-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:57 [INFO] notebook - Data before 2018-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:54:59 [INFO] notebook - Data before 2018-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:02 [INFO] notebook - Data before 2018-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:04 [INFO] notebook - Data before 2018-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:07 [INFO] notebook - Data before 2018-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:09 [INFO] notebook - Data before 2018-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:12 [INFO] notebook - Data before 2018-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:14 [INFO] notebook - Data before 2018-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:17 [INFO] notebook - Data before 2018-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:20 [INFO] notebook - Data before 2018-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:22 [INFO] notebook - Data before 2018-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:25 [INFO] notebook - Data before 2018-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:28 [INFO] notebook - Data before 2018-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:30 [INFO] notebook - Data before 2018-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:33 [INFO] notebook - Data before 2018-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:35 [INFO] notebook - Data before 2018-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:38 [INFO] notebook - Data before 2018-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:41 [INFO] notebook - Data before 2018-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:44 [INFO] notebook - Data before 2018-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:47 [INFO] notebook - Data before 2018-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:49 [INFO] notebook - Data before 2018-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:52 [INFO] notebook - Data before 2018-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:55 [INFO] notebook - Data before 2018-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:55:58 [INFO] notebook - Data before 2018-07-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:01 [INFO] notebook - Data before 2018-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:04 [INFO] notebook - Data before 2018-07-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:07 [INFO] notebook - Data before 2018-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:09 [INFO] notebook - Data before 2018-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:12 [INFO] notebook - Data before 2018-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:15 [INFO] notebook - Data before 2018-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:18 [INFO] notebook - Data before 2018-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:21 [INFO] notebook - Data before 2018-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:24 [INFO] notebook - Data before 2018-08-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:27 [INFO] notebook - Data before 2018-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:30 [INFO] notebook - Data before 2018-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:33 [INFO] notebook - Data before 2018-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:36 [INFO] notebook - Data before 2018-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:39 [INFO] notebook - Data before 2018-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:42 [INFO] notebook - Data before 2018-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:45 [INFO] notebook - Data before 2018-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:48 [INFO] notebook - Data before 2018-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:51 [INFO] notebook - Data before 2018-08-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:54 [INFO] notebook - Data before 2018-08-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:56:58 [INFO] notebook - Data before 2018-08-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:01 [INFO] notebook - Data before 2018-08-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:04 [INFO] notebook - Data before 2018-08-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:07 [INFO] notebook - Data before 2018-08-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:10 [INFO] notebook - Data before 2018-08-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:13 [INFO] notebook - Data before 2018-08-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:17 [INFO] notebook - Data before 2018-08-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:20 [INFO] notebook - Data before 2018-08-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:23 [INFO] notebook - Data before 2018-08-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:26 [INFO] notebook - Data before 2018-08-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:29 [INFO] notebook - Data before 2018-08-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:33 [INFO] notebook - Data before 2018-08-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:36 [INFO] notebook - Data before 2018-08-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:39 [INFO] notebook - Data before 2018-08-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:43 [INFO] notebook - Data before 2018-08-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:46 [INFO] notebook - Data before 2018-08-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:50 [INFO] notebook - Data before 2018-08-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:53 [INFO] notebook - Data before 2018-09-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:57:56 [INFO] notebook - Data before 2018-09-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:00 [INFO] notebook - Data before 2018-09-03T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 22:58:03 [INFO] notebook - Data before 2018-09-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:07 [INFO] notebook - Data before 2018-09-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:10 [INFO] notebook - Data before 2018-09-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:14 [INFO] notebook - Data before 2018-09-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:17 [INFO] notebook - Data before 2018-09-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:21 [INFO] notebook - Data before 2018-09-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:24 [INFO] notebook - Data before 2018-09-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:28 [INFO] notebook - Data before 2018-09-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:31 [INFO] notebook - Data before 2018-09-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:35 [INFO] notebook - Data before 2018-09-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:38 [INFO] notebook - Data before 2018-09-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:42 [INFO] notebook - Data before 2018-09-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:45 [INFO] notebook - Data before 2018-09-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:49 [INFO] notebook - Data before 2018-09-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:53 [INFO] notebook - Data before 2018-09-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:58:56 [INFO] notebook - Data before 2018-09-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:00 [INFO] notebook - Data before 2018-09-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:04 [INFO] notebook - Data before 2018-09-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:07 [INFO] notebook - Data before 2018-09-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:11 [INFO] notebook - Data before 2018-09-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:15 [INFO] notebook - Data before 2018-09-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:18 [INFO] notebook - Data before 2018-09-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:22 [INFO] notebook - Data before 2018-09-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:26 [INFO] notebook - Data before 2018-09-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:29 [INFO] notebook - Data before 2018-09-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:33 [INFO] notebook - Data before 2018-09-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:37 [INFO] notebook - Data before 2018-09-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:41 [INFO] notebook - Data before 2018-10-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:45 [INFO] notebook - Data before 2018-10-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:48 [INFO] notebook - Data before 2018-10-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:52 [INFO] notebook - Data before 2018-10-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 22:59:56 [INFO] notebook - Data before 2018-10-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:00 [INFO] notebook - Data before 2018-10-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:04 [INFO] notebook - Data before 2018-10-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:07 [INFO] notebook - Data before 2018-10-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:11 [INFO] notebook - Data before 2018-10-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:15 [INFO] notebook - Data before 2018-10-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:19 [INFO] notebook - Data before 2018-10-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:23 [INFO] notebook - Data before 2018-10-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:27 [INFO] notebook - Data before 2018-10-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:31 [INFO] notebook - Data before 2018-10-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:35 [INFO] notebook - Data before 2018-10-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:39 [INFO] notebook - Data before 2018-10-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:43 [INFO] notebook - Data before 2018-10-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:47 [INFO] notebook - Data before 2018-10-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:51 [INFO] notebook - Data before 2018-10-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:55 [INFO] notebook - Data before 2018-10-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:00:59 [INFO] notebook - Data before 2018-10-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:03 [INFO] notebook - Data before 2018-10-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:07 [INFO] notebook - Data before 2018-10-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:11 [INFO] notebook - Data before 2018-10-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:15 [INFO] notebook - Data before 2018-10-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:19 [INFO] notebook - Data before 2018-10-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:23 [INFO] notebook - Data before 2018-10-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:27 [INFO] notebook - Data before 2018-10-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:31 [INFO] notebook - Data before 2018-10-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:35 [INFO] notebook - Data before 2018-10-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:39 [INFO] notebook - Data before 2018-10-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:43 [INFO] notebook - Data before 2018-11-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:48 [INFO] notebook - Data before 2018-11-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:52 [INFO] notebook - Data before 2018-11-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:01:56 [INFO] notebook - Data before 2018-11-04T14:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:00 [INFO] notebook - Data before 2018-11-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:04 [INFO] notebook - Data before 2018-11-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:08 [INFO] notebook - Data before 2018-11-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:13 [INFO] notebook - Data before 2018-11-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:17 [INFO] notebook - Data before 2018-11-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:21 [INFO] notebook - Data before 2018-11-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:25 [INFO] notebook - Data before 2018-11-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:29 [INFO] notebook - Data before 2018-11-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:34 [INFO] notebook - Data before 2018-11-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:38 [INFO] notebook - Data before 2018-11-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:42 [INFO] notebook - Data before 2018-11-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:47 [INFO] notebook - Data before 2018-11-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:51 [INFO] notebook - Data before 2018-11-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:02:55 [INFO] notebook - Data before 2018-11-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:00 [INFO] notebook - Data before 2018-11-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:04 [INFO] notebook - Data before 2018-11-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:08 [INFO] notebook - Data before 2018-11-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:13 [INFO] notebook - Data before 2018-11-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:17 [INFO] notebook - Data before 2018-11-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:22 [INFO] notebook - Data before 2018-11-24T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 23:03:26 [INFO] notebook - Data before 2018-11-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:30 [INFO] notebook - Data before 2018-11-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:35 [INFO] notebook - Data before 2018-11-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:41 [INFO] notebook - Data before 2018-11-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:46 [INFO] notebook - Data before 2018-11-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:50 [INFO] notebook - Data before 2018-11-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:55 [INFO] notebook - Data before 2018-12-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:03:59 [INFO] notebook - Data before 2018-12-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:04 [INFO] notebook - Data before 2018-12-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:08 [INFO] notebook - Data before 2018-12-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:13 [INFO] notebook - Data before 2018-12-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:18 [INFO] notebook - Data before 2018-12-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:22 [INFO] notebook - Data before 2018-12-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:27 [INFO] notebook - Data before 2018-12-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:31 [INFO] notebook - Data before 2018-12-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:36 [INFO] notebook - Data before 2018-12-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:41 [INFO] notebook - Data before 2018-12-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:45 [INFO] notebook - Data before 2018-12-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:50 [INFO] notebook - Data before 2018-12-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:55 [INFO] notebook - Data before 2018-12-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:04:59 [INFO] notebook - Data before 2018-12-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:04 [INFO] notebook - Data before 2018-12-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:09 [INFO] notebook - Data before 2018-12-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:14 [INFO] notebook - Data before 2018-12-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:18 [INFO] notebook - Data before 2018-12-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:23 [INFO] notebook - Data before 2018-12-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:28 [INFO] notebook - Data before 2018-12-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:32 [INFO] notebook - Data before 2018-12-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:37 [INFO] notebook - Data before 2018-12-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:42 [INFO] notebook - Data before 2018-12-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:48 [INFO] notebook - Data before 2018-12-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:52 [INFO] notebook - Data before 2018-12-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:05:57 [INFO] notebook - Data before 2018-12-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:02 [INFO] notebook - Data before 2018-12-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:07 [INFO] notebook - Data before 2018-12-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:12 [INFO] notebook - Data before 2018-12-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:16 [INFO] notebook - Data before 2018-12-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:21 [INFO] notebook - Data before 2019-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:26 [INFO] notebook - Data before 2019-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:31 [INFO] notebook - Data before 2019-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:36 [INFO] notebook - Data before 2019-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:41 [INFO] notebook - Data before 2019-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:46 [INFO] notebook - Data before 2019-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:51 [INFO] notebook - Data before 2019-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:06:56 [INFO] notebook - Data before 2019-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:01 [INFO] notebook - Data before 2019-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:06 [INFO] notebook - Data before 2019-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:11 [INFO] notebook - Data before 2019-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:16 [INFO] notebook - Data before 2019-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:21 [INFO] notebook - Data before 2019-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:27 [INFO] notebook - Data before 2019-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:32 [INFO] notebook - Data before 2019-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:37 [INFO] notebook - Data before 2019-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:42 [INFO] notebook - Data before 2019-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:47 [INFO] notebook - Data before 2019-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:52 [INFO] notebook - Data before 2019-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:07:57 [INFO] notebook - Data before 2019-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:03 [INFO] notebook - Data before 2019-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:08 [INFO] notebook - Data before 2019-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:13 [INFO] notebook - Data before 2019-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:18 [INFO] notebook - Data before 2019-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:23 [INFO] notebook - Data before 2019-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:28 [INFO] notebook - Data before 2019-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:34 [INFO] notebook - Data before 2019-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:39 [INFO] notebook - Data before 2019-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:44 [INFO] notebook - Data before 2019-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:49 [INFO] notebook - Data before 2019-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:08:55 [INFO] notebook - Data before 2019-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:01 [INFO] notebook - Data before 2019-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:06 [INFO] notebook - Data before 2019-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:11 [INFO] notebook - Data before 2019-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:16 [INFO] notebook - Data before 2019-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:22 [INFO] notebook - Data before 2019-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:27 [INFO] notebook - Data before 2019-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:32 [INFO] notebook - Data before 2019-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:38 [INFO] notebook - Data before 2019-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:43 [INFO] notebook - Data before 2019-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:48 [INFO] notebook - Data before 2019-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:54 [INFO] notebook - Data before 2019-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:09:59 [INFO] notebook - Data before 2019-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:05 [INFO] notebook - Data before 2019-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:10 [INFO] notebook - Data before 2019-02-14T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 23:10:15 [INFO] notebook - Data before 2019-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:21 [INFO] notebook - Data before 2019-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:26 [INFO] notebook - Data before 2019-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:32 [INFO] notebook - Data before 2019-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:37 [INFO] notebook - Data before 2019-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:43 [INFO] notebook - Data before 2019-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:48 [INFO] notebook - Data before 2019-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:54 [INFO] notebook - Data before 2019-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:10:59 [INFO] notebook - Data before 2019-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:05 [INFO] notebook - Data before 2019-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:11 [INFO] notebook - Data before 2019-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:16 [INFO] notebook - Data before 2019-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:22 [INFO] notebook - Data before 2019-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:28 [INFO] notebook - Data before 2019-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:33 [INFO] notebook - Data before 2019-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:39 [INFO] notebook - Data before 2019-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:44 [INFO] notebook - Data before 2019-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:50 [INFO] notebook - Data before 2019-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:11:56 [INFO] notebook - Data before 2019-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:12:01 [INFO] notebook - Data before 2019-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:12:07 [INFO] notebook - Data before 2019-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:12:13 [INFO] notebook - Data before 2019-03-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:12:19 [INFO] notebook - Data before 2019-03-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:12:26 [INFO] notebook - Data before 2019-03-10T16:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:12:32 [INFO] notebook - Data before 2019-03-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:12:38 [INFO] notebook - Data before 2019-03-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:12:44 [INFO] notebook - Data before 2019-03-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:12:50 [INFO] notebook - Data before 2019-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:12:56 [INFO] notebook - Data before 2019-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:01 [INFO] notebook - Data before 2019-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:07 [INFO] notebook - Data before 2019-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:13 [INFO] notebook - Data before 2019-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:19 [INFO] notebook - Data before 2019-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:25 [INFO] notebook - Data before 2019-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:31 [INFO] notebook - Data before 2019-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:37 [INFO] notebook - Data before 2019-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:42 [INFO] notebook - Data before 2019-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:48 [INFO] notebook - Data before 2019-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:13:54 [INFO] notebook - Data before 2019-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:00 [INFO] notebook - Data before 2019-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:06 [INFO] notebook - Data before 2019-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:12 [INFO] notebook - Data before 2019-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:18 [INFO] notebook - Data before 2019-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:24 [INFO] notebook - Data before 2019-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:30 [INFO] notebook - Data before 2019-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:36 [INFO] notebook - Data before 2019-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:42 [INFO] notebook - Data before 2019-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:49 [INFO] notebook - Data before 2019-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:14:55 [INFO] notebook - Data before 2019-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:01 [INFO] notebook - Data before 2019-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:07 [INFO] notebook - Data before 2019-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:13 [INFO] notebook - Data before 2019-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:19 [INFO] notebook - Data before 2019-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:25 [INFO] notebook - Data before 2019-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:32 [INFO] notebook - Data before 2019-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:38 [INFO] notebook - Data before 2019-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:45 [INFO] notebook - Data before 2019-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:51 [INFO] notebook - Data before 2019-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:15:57 [INFO] notebook - Data before 2019-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:03 [INFO] notebook - Data before 2019-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:10 [INFO] notebook - Data before 2019-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:16 [INFO] notebook - Data before 2019-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:22 [INFO] notebook - Data before 2019-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:29 [INFO] notebook - Data before 2019-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:35 [INFO] notebook - Data before 2019-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:41 [INFO] notebook - Data before 2019-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:48 [INFO] notebook - Data before 2019-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:16:55 [INFO] notebook - Data before 2019-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:01 [INFO] notebook - Data before 2019-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:08 [INFO] notebook - Data before 2019-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:15 [INFO] notebook - Data before 2019-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:21 [INFO] notebook - Data before 2019-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:28 [INFO] notebook - Data before 2019-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:34 [INFO] notebook - Data before 2019-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:41 [INFO] notebook - Data before 2019-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:47 [INFO] notebook - Data before 2019-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:17:54 [INFO] notebook - Data before 2019-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:00 [INFO] notebook - Data before 2019-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:07 [INFO] notebook - Data before 2019-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:13 [INFO] notebook - Data before 2019-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:19 [INFO] notebook - Data before 2019-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:26 [INFO] notebook - Data before 2019-05-07T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 23:18:32 [INFO] notebook - Data before 2019-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:39 [INFO] notebook - Data before 2019-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:46 [INFO] notebook - Data before 2019-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:52 [INFO] notebook - Data before 2019-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:18:59 [INFO] notebook - Data before 2019-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:05 [INFO] notebook - Data before 2019-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:12 [INFO] notebook - Data before 2019-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:19 [INFO] notebook - Data before 2019-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:25 [INFO] notebook - Data before 2019-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:32 [INFO] notebook - Data before 2019-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:38 [INFO] notebook - Data before 2019-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:45 [INFO] notebook - Data before 2019-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:52 [INFO] notebook - Data before 2019-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:19:58 [INFO] notebook - Data before 2019-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:05 [INFO] notebook - Data before 2019-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:12 [INFO] notebook - Data before 2019-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:18 [INFO] notebook - Data before 2019-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:25 [INFO] notebook - Data before 2019-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:31 [INFO] notebook - Data before 2019-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:38 [INFO] notebook - Data before 2019-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:45 [INFO] notebook - Data before 2019-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:52 [INFO] notebook - Data before 2019-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:20:59 [INFO] notebook - Data before 2019-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:05 [INFO] notebook - Data before 2019-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:12 [INFO] notebook - Data before 2019-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:19 [INFO] notebook - Data before 2019-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:26 [INFO] notebook - Data before 2019-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:32 [INFO] notebook - Data before 2019-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:39 [INFO] notebook - Data before 2019-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:46 [INFO] notebook - Data before 2019-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:21:53 [INFO] notebook - Data before 2019-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:00 [INFO] notebook - Data before 2019-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:07 [INFO] notebook - Data before 2019-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:13 [INFO] notebook - Data before 2019-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:20 [INFO] notebook - Data before 2019-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:27 [INFO] notebook - Data before 2019-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:34 [INFO] notebook - Data before 2019-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:41 [INFO] notebook - Data before 2019-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:48 [INFO] notebook - Data before 2019-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:22:55 [INFO] notebook - Data before 2019-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:02 [INFO] notebook - Data before 2019-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:09 [INFO] notebook - Data before 2019-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:16 [INFO] notebook - Data before 2019-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:24 [INFO] notebook - Data before 2019-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:31 [INFO] notebook - Data before 2019-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:38 [INFO] notebook - Data before 2019-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:45 [INFO] notebook - Data before 2019-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:52 [INFO] notebook - Data before 2019-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:23:59 [INFO] notebook - Data before 2019-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:06 [INFO] notebook - Data before 2019-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:13 [INFO] notebook - Data before 2019-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:21 [INFO] notebook - Data before 2019-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:28 [INFO] notebook - Data before 2019-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:35 [INFO] notebook - Data before 2019-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:42 [INFO] notebook - Data before 2019-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:49 [INFO] notebook - Data before 2019-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:24:56 [INFO] notebook - Data before 2019-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:03 [INFO] notebook - Data before 2019-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:11 [INFO] notebook - Data before 2019-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:18 [INFO] notebook - Data before 2019-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:25 [INFO] notebook - Data before 2019-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:33 [INFO] notebook - Data before 2019-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:40 [INFO] notebook - Data before 2019-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:49 [INFO] notebook - Data before 2019-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:25:56 [INFO] notebook - Data before 2019-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:03 [INFO] notebook - Data before 2019-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:11 [INFO] notebook - Data before 2019-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:18 [INFO] notebook - Data before 2019-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:26 [INFO] notebook - Data before 2019-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:33 [INFO] notebook - Data before 2019-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:41 [INFO] notebook - Data before 2019-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:48 [INFO] notebook - Data before 2019-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:26:56 [INFO] notebook - Data before 2019-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:03 [INFO] notebook - Data before 2019-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:11 [INFO] notebook - Data before 2019-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:18 [INFO] notebook - Data before 2019-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:26 [INFO] notebook - Data before 2019-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:34 [INFO] notebook - Data before 2019-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:41 [INFO] notebook - Data before 2019-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:49 [INFO] notebook - Data before 2019-07-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:27:56 [INFO] notebook - Data before 2019-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:04 [INFO] notebook - Data before 2019-07-28T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 23:28:11 [INFO] notebook - Data before 2019-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:19 [INFO] notebook - Data before 2019-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:27 [INFO] notebook - Data before 2019-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:34 [INFO] notebook - Data before 2019-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:42 [INFO] notebook - Data before 2019-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:50 [INFO] notebook - Data before 2019-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:28:57 [INFO] notebook - Data before 2019-08-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:05 [INFO] notebook - Data before 2019-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:13 [INFO] notebook - Data before 2019-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:20 [INFO] notebook - Data before 2019-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:28 [INFO] notebook - Data before 2019-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:36 [INFO] notebook - Data before 2019-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:44 [INFO] notebook - Data before 2019-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:51 [INFO] notebook - Data before 2019-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:29:59 [INFO] notebook - Data before 2019-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:07 [INFO] notebook - Data before 2019-08-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:15 [INFO] notebook - Data before 2019-08-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:23 [INFO] notebook - Data before 2019-08-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:31 [INFO] notebook - Data before 2019-08-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:40 [INFO] notebook - Data before 2019-08-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:47 [INFO] notebook - Data before 2019-08-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:30:55 [INFO] notebook - Data before 2019-08-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:03 [INFO] notebook - Data before 2019-08-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:11 [INFO] notebook - Data before 2019-08-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:19 [INFO] notebook - Data before 2019-08-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:27 [INFO] notebook - Data before 2019-08-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:35 [INFO] notebook - Data before 2019-08-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:43 [INFO] notebook - Data before 2019-08-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:51 [INFO] notebook - Data before 2019-08-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:31:59 [INFO] notebook - Data before 2019-08-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:07 [INFO] notebook - Data before 2019-08-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:15 [INFO] notebook - Data before 2019-08-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:24 [INFO] notebook - Data before 2019-08-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:33 [INFO] notebook - Data before 2019-08-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:40 [INFO] notebook - Data before 2019-09-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:48 [INFO] notebook - Data before 2019-09-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:32:56 [INFO] notebook - Data before 2019-09-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:04 [INFO] notebook - Data before 2019-09-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:12 [INFO] notebook - Data before 2019-09-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:20 [INFO] notebook - Data before 2019-09-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:28 [INFO] notebook - Data before 2019-09-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:36 [INFO] notebook - Data before 2019-09-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:45 [INFO] notebook - Data before 2019-09-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:33:53 [INFO] notebook - Data before 2019-09-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:01 [INFO] notebook - Data before 2019-09-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:09 [INFO] notebook - Data before 2019-09-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:18 [INFO] notebook - Data before 2019-09-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:26 [INFO] notebook - Data before 2019-09-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:34 [INFO] notebook - Data before 2019-09-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:42 [INFO] notebook - Data before 2019-09-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:51 [INFO] notebook - Data before 2019-09-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:34:59 [INFO] notebook - Data before 2019-09-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:07 [INFO] notebook - Data before 2019-09-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:16 [INFO] notebook - Data before 2019-09-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:24 [INFO] notebook - Data before 2019-09-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:32 [INFO] notebook - Data before 2019-09-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:41 [INFO] notebook - Data before 2019-09-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:49 [INFO] notebook - Data before 2019-09-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:35:57 [INFO] notebook - Data before 2019-09-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:06 [INFO] notebook - Data before 2019-09-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:15 [INFO] notebook - Data before 2019-09-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:23 [INFO] notebook - Data before 2019-09-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:31 [INFO] notebook - Data before 2019-09-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:40 [INFO] notebook - Data before 2019-09-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:48 [INFO] notebook - Data before 2019-10-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:36:57 [INFO] notebook - Data before 2019-10-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:05 [INFO] notebook - Data before 2019-10-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:14 [INFO] notebook - Data before 2019-10-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:22 [INFO] notebook - Data before 2019-10-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:30 [INFO] notebook - Data before 2019-10-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:39 [INFO] notebook - Data before 2019-10-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:48 [INFO] notebook - Data before 2019-10-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:37:57 [INFO] notebook - Data before 2019-10-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:05 [INFO] notebook - Data before 2019-10-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:15 [INFO] notebook - Data before 2019-10-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:23 [INFO] notebook - Data before 2019-10-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:31 [INFO] notebook - Data before 2019-10-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:40 [INFO] notebook - Data before 2019-10-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:49 [INFO] notebook - Data before 2019-10-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:38:58 [INFO] notebook - Data before 2019-10-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:39:07 [INFO] notebook - Data before 2019-10-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:39:15 [INFO] notebook - Data before 2019-10-18T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 23:39:25 [INFO] notebook - Data before 2019-10-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:39:35 [INFO] notebook - Data before 2019-10-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:39:45 [INFO] notebook - Data before 2019-10-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:39:53 [INFO] notebook - Data before 2019-10-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:02 [INFO] notebook - Data before 2019-10-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:11 [INFO] notebook - Data before 2019-10-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:21 [INFO] notebook - Data before 2019-10-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:29 [INFO] notebook - Data before 2019-10-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:38 [INFO] notebook - Data before 2019-10-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:46 [INFO] notebook - Data before 2019-10-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:40:55 [INFO] notebook - Data before 2019-10-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:41:04 [INFO] notebook - Data before 2019-10-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:41:13 [INFO] notebook - Data before 2019-10-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:41:22 [INFO] notebook - Data before 2019-11-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:41:31 [INFO] notebook - Data before 2019-11-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-20 23:41:40 [INFO] notebook - Data before 2019-11-03T14:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:41:48 [INFO] notebook - Data before 2019-11-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:41:57 [INFO] notebook - Data before 2019-11-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:42:06 [INFO] notebook - Data before 2019-11-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:42:15 [INFO] notebook - Data before 2019-11-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:42:25 [INFO] notebook - Data before 2019-11-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:42:34 [INFO] notebook - Data before 2019-11-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:42:43 [INFO] notebook - Data before 2019-11-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:42:52 [INFO] notebook - Data before 2019-11-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:01 [INFO] notebook - Data before 2019-11-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:10 [INFO] notebook - Data before 2019-11-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:19 [INFO] notebook - Data before 2019-11-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:28 [INFO] notebook - Data before 2019-11-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:37 [INFO] notebook - Data before 2019-11-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:46 [INFO] notebook - Data before 2019-11-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:43:56 [INFO] notebook - Data before 2019-11-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:44:05 [INFO] notebook - Data before 2019-11-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:44:14 [INFO] notebook - Data before 2019-11-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:44:23 [INFO] notebook - Data before 2019-11-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:44:33 [INFO] notebook - Data before 2019-11-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:44:42 [INFO] notebook - Data before 2019-11-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:44:51 [INFO] notebook - Data before 2019-11-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:00 [INFO] notebook - Data before 2019-11-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:09 [INFO] notebook - Data before 2019-11-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:18 [INFO] notebook - Data before 2019-11-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:27 [INFO] notebook - Data before 2019-11-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:36 [INFO] notebook - Data before 2019-11-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:45 [INFO] notebook - Data before 2019-11-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:45:54 [INFO] notebook - Data before 2019-12-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:46:04 [INFO] notebook - Data before 2019-12-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:46:14 [INFO] notebook - Data before 2019-12-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:46:23 [INFO] notebook - Data before 2019-12-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:46:32 [INFO] notebook - Data before 2019-12-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:46:42 [INFO] notebook - Data before 2019-12-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:46:51 [INFO] notebook - Data before 2019-12-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:00 [INFO] notebook - Data before 2019-12-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:09 [INFO] notebook - Data before 2019-12-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:18 [INFO] notebook - Data before 2019-12-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:28 [INFO] notebook - Data before 2019-12-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:37 [INFO] notebook - Data before 2019-12-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:46 [INFO] notebook - Data before 2019-12-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:47:56 [INFO] notebook - Data before 2019-12-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:48:05 [INFO] notebook - Data before 2019-12-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:48:14 [INFO] notebook - Data before 2019-12-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:48:24 [INFO] notebook - Data before 2019-12-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:48:34 [INFO] notebook - Data before 2019-12-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:48:44 [INFO] notebook - Data before 2019-12-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:48:54 [INFO] notebook - Data before 2019-12-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:49:03 [INFO] notebook - Data before 2019-12-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:49:13 [INFO] notebook - Data before 2019-12-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:49:22 [INFO] notebook - Data before 2019-12-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:49:32 [INFO] notebook - Data before 2019-12-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:49:42 [INFO] notebook - Data before 2019-12-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:49:51 [INFO] notebook - Data before 2019-12-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:01 [INFO] notebook - Data before 2019-12-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:10 [INFO] notebook - Data before 2019-12-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:20 [INFO] notebook - Data before 2019-12-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:29 [INFO] notebook - Data before 2019-12-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:39 [INFO] notebook - Data before 2019-12-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:49 [INFO] notebook - Data before 2020-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:50:59 [INFO] notebook - Data before 2020-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:51:09 [INFO] notebook - Data before 2020-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:51:18 [INFO] notebook - Data before 2020-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:51:28 [INFO] notebook - Data before 2020-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:51:37 [INFO] notebook - Data before 2020-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:51:47 [INFO] notebook - Data before 2020-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:51:56 [INFO] notebook - Data before 2020-01-08T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 23:52:06 [INFO] notebook - Data before 2020-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:52:16 [INFO] notebook - Data before 2020-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:52:26 [INFO] notebook - Data before 2020-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:52:35 [INFO] notebook - Data before 2020-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:52:45 [INFO] notebook - Data before 2020-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:52:54 [INFO] notebook - Data before 2020-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:53:05 [INFO] notebook - Data before 2020-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:53:16 [INFO] notebook - Data before 2020-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:53:27 [INFO] notebook - Data before 2020-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:53:37 [INFO] notebook - Data before 2020-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:53:47 [INFO] notebook - Data before 2020-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:53:56 [INFO] notebook - Data before 2020-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:54:06 [INFO] notebook - Data before 2020-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:54:17 [INFO] notebook - Data before 2020-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:54:27 [INFO] notebook - Data before 2020-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:54:36 [INFO] notebook - Data before 2020-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:54:46 [INFO] notebook - Data before 2020-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:54:56 [INFO] notebook - Data before 2020-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:55:06 [INFO] notebook - Data before 2020-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:55:17 [INFO] notebook - Data before 2020-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:55:27 [INFO] notebook - Data before 2020-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:55:37 [INFO] notebook - Data before 2020-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:55:47 [INFO] notebook - Data before 2020-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:55:58 [INFO] notebook - Data before 2020-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:56:10 [INFO] notebook - Data before 2020-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:56:21 [INFO] notebook - Data before 2020-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:56:31 [INFO] notebook - Data before 2020-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:56:42 [INFO] notebook - Data before 2020-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:56:52 [INFO] notebook - Data before 2020-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:57:02 [INFO] notebook - Data before 2020-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:57:12 [INFO] notebook - Data before 2020-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:57:22 [INFO] notebook - Data before 2020-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:57:32 [INFO] notebook - Data before 2020-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:57:43 [INFO] notebook - Data before 2020-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:57:53 [INFO] notebook - Data before 2020-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:58:03 [INFO] notebook - Data before 2020-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:58:15 [INFO] notebook - Data before 2020-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:58:25 [INFO] notebook - Data before 2020-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:58:36 [INFO] notebook - Data before 2020-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:58:46 [INFO] notebook - Data before 2020-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:58:56 [INFO] notebook - Data before 2020-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:59:06 [INFO] notebook - Data before 2020-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:59:16 [INFO] notebook - Data before 2020-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:59:26 [INFO] notebook - Data before 2020-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:59:37 [INFO] notebook - Data before 2020-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:59:48 [INFO] notebook - Data before 2020-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-20 23:59:59 [INFO] notebook - Data before 2020-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:00:10 [INFO] notebook - Data before 2020-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:00:21 [INFO] notebook - Data before 2020-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:00:31 [INFO] notebook - Data before 2020-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:00:42 [INFO] notebook - Data before 2020-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:00:52 [INFO] notebook - Data before 2020-02-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:01:02 [INFO] notebook - Data before 2020-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:01:13 [INFO] notebook - Data before 2020-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:01:23 [INFO] notebook - Data before 2020-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:01:34 [INFO] notebook - Data before 2020-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:01:44 [INFO] notebook - Data before 2020-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:01:55 [INFO] notebook - Data before 2020-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:02:05 [INFO] notebook - Data before 2020-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:02:15 [INFO] notebook - Data before 2020-03-08T16:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:02:26 [INFO] notebook - Data before 2020-03-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:02:36 [INFO] notebook - Data before 2020-03-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:02:47 [INFO] notebook - Data before 2020-03-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:02:57 [INFO] notebook - Data before 2020-03-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:03:08 [INFO] notebook - Data before 2020-03-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:03:19 [INFO] notebook - Data before 2020-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:03:30 [INFO] notebook - Data before 2020-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:03:41 [INFO] notebook - Data before 2020-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:03:51 [INFO] notebook - Data before 2020-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:04:02 [INFO] notebook - Data before 2020-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:04:12 [INFO] notebook - Data before 2020-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:04:23 [INFO] notebook - Data before 2020-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:04:34 [INFO] notebook - Data before 2020-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:04:45 [INFO] notebook - Data before 2020-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:04:55 [INFO] notebook - Data before 2020-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:05:06 [INFO] notebook - Data before 2020-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:05:16 [INFO] notebook - Data before 2020-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:05:27 [INFO] notebook - Data before 2020-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:05:38 [INFO] notebook - Data before 2020-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:05:49 [INFO] notebook - Data before 2020-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:06:00 [INFO] notebook - Data before 2020-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:06:11 [INFO] notebook - Data before 2020-03-30T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 00:06:22 [INFO] notebook - Data before 2020-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:06:33 [INFO] notebook - Data before 2020-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:06:44 [INFO] notebook - Data before 2020-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:06:55 [INFO] notebook - Data before 2020-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:07:06 [INFO] notebook - Data before 2020-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:07:16 [INFO] notebook - Data before 2020-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:07:27 [INFO] notebook - Data before 2020-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:07:38 [INFO] notebook - Data before 2020-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:07:49 [INFO] notebook - Data before 2020-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:08:00 [INFO] notebook - Data before 2020-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:08:11 [INFO] notebook - Data before 2020-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:08:21 [INFO] notebook - Data before 2020-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:08:33 [INFO] notebook - Data before 2020-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:08:44 [INFO] notebook - Data before 2020-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:08:55 [INFO] notebook - Data before 2020-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:09:06 [INFO] notebook - Data before 2020-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:09:17 [INFO] notebook - Data before 2020-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:09:28 [INFO] notebook - Data before 2020-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:09:39 [INFO] notebook - Data before 2020-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:09:50 [INFO] notebook - Data before 2020-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:10:01 [INFO] notebook - Data before 2020-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:10:12 [INFO] notebook - Data before 2020-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:10:23 [INFO] notebook - Data before 2020-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:10:34 [INFO] notebook - Data before 2020-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:10:45 [INFO] notebook - Data before 2020-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:10:56 [INFO] notebook - Data before 2020-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:11:08 [INFO] notebook - Data before 2020-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:11:19 [INFO] notebook - Data before 2020-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:11:30 [INFO] notebook - Data before 2020-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:11:41 [INFO] notebook - Data before 2020-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:11:52 [INFO] notebook - Data before 2020-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:12:04 [INFO] notebook - Data before 2020-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:12:15 [INFO] notebook - Data before 2020-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:12:27 [INFO] notebook - Data before 2020-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:12:39 [INFO] notebook - Data before 2020-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:12:50 [INFO] notebook - Data before 2020-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:13:01 [INFO] notebook - Data before 2020-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:13:13 [INFO] notebook - Data before 2020-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:13:24 [INFO] notebook - Data before 2020-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:13:35 [INFO] notebook - Data before 2020-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:13:46 [INFO] notebook - Data before 2020-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:13:57 [INFO] notebook - Data before 2020-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:14:09 [INFO] notebook - Data before 2020-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:14:20 [INFO] notebook - Data before 2020-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:14:31 [INFO] notebook - Data before 2020-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:14:43 [INFO] notebook - Data before 2020-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:14:55 [INFO] notebook - Data before 2020-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:15:07 [INFO] notebook - Data before 2020-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:15:18 [INFO] notebook - Data before 2020-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:15:30 [INFO] notebook - Data before 2020-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:15:42 [INFO] notebook - Data before 2020-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:15:54 [INFO] notebook - Data before 2020-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:16:05 [INFO] notebook - Data before 2020-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:16:17 [INFO] notebook - Data before 2020-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:16:28 [INFO] notebook - Data before 2020-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:16:39 [INFO] notebook - Data before 2020-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:16:51 [INFO] notebook - Data before 2020-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:17:03 [INFO] notebook - Data before 2020-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:17:15 [INFO] notebook - Data before 2020-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:17:27 [INFO] notebook - Data before 2020-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:17:38 [INFO] notebook - Data before 2020-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:17:50 [INFO] notebook - Data before 2020-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:18:01 [INFO] notebook - Data before 2020-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:18:13 [INFO] notebook - Data before 2020-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:18:25 [INFO] notebook - Data before 2020-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:18:36 [INFO] notebook - Data before 2020-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:18:48 [INFO] notebook - Data before 2020-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:19:00 [INFO] notebook - Data before 2020-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:19:12 [INFO] notebook - Data before 2020-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:19:23 [INFO] notebook - Data before 2020-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:19:35 [INFO] notebook - Data before 2020-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:19:47 [INFO] notebook - Data before 2020-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:19:59 [INFO] notebook - Data before 2020-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:20:11 [INFO] notebook - Data before 2020-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:20:22 [INFO] notebook - Data before 2020-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:20:34 [INFO] notebook - Data before 2020-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:20:46 [INFO] notebook - Data before 2020-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:20:58 [INFO] notebook - Data before 2020-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:21:10 [INFO] notebook - Data before 2020-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:21:22 [INFO] notebook - Data before 2020-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:21:34 [INFO] notebook - Data before 2020-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:21:46 [INFO] notebook - Data before 2020-06-20T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 00:21:58 [INFO] notebook - Data before 2020-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:22:10 [INFO] notebook - Data before 2020-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:22:23 [INFO] notebook - Data before 2020-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:22:35 [INFO] notebook - Data before 2020-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:22:47 [INFO] notebook - Data before 2020-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:22:59 [INFO] notebook - Data before 2020-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:23:11 [INFO] notebook - Data before 2020-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:23:23 [INFO] notebook - Data before 2020-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:23:36 [INFO] notebook - Data before 2020-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:23:48 [INFO] notebook - Data before 2020-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:24:00 [INFO] notebook - Data before 2020-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:24:12 [INFO] notebook - Data before 2020-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:24:24 [INFO] notebook - Data before 2020-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:24:37 [INFO] notebook - Data before 2020-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:24:49 [INFO] notebook - Data before 2020-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:25:01 [INFO] notebook - Data before 2020-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:25:14 [INFO] notebook - Data before 2020-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:25:26 [INFO] notebook - Data before 2020-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:25:38 [INFO] notebook - Data before 2020-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:25:50 [INFO] notebook - Data before 2020-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:26:02 [INFO] notebook - Data before 2020-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:26:14 [INFO] notebook - Data before 2020-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:26:26 [INFO] notebook - Data before 2020-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:26:38 [INFO] notebook - Data before 2020-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:26:51 [INFO] notebook - Data before 2020-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:27:03 [INFO] notebook - Data before 2020-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:27:15 [INFO] notebook - Data before 2020-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:27:29 [INFO] notebook - Data before 2020-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:27:42 [INFO] notebook - Data before 2020-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:27:55 [INFO] notebook - Data before 2020-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:28:07 [INFO] notebook - Data before 2020-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:28:19 [INFO] notebook - Data before 2020-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:28:32 [INFO] notebook - Data before 2020-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:28:44 [INFO] notebook - Data before 2020-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:28:56 [INFO] notebook - Data before 2020-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:29:08 [INFO] notebook - Data before 2020-07-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:29:21 [INFO] notebook - Data before 2020-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:29:33 [INFO] notebook - Data before 2020-07-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:29:45 [INFO] notebook - Data before 2020-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:29:57 [INFO] notebook - Data before 2020-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:30:10 [INFO] notebook - Data before 2020-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:30:22 [INFO] notebook - Data before 2020-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:30:34 [INFO] notebook - Data before 2020-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:30:47 [INFO] notebook - Data before 2020-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:30:59 [INFO] notebook - Data before 2020-08-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:31:12 [INFO] notebook - Data before 2020-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:31:24 [INFO] notebook - Data before 2020-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:31:37 [INFO] notebook - Data before 2020-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:31:50 [INFO] notebook - Data before 2020-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:32:02 [INFO] notebook - Data before 2020-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:32:15 [INFO] notebook - Data before 2020-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:32:27 [INFO] notebook - Data before 2020-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:32:40 [INFO] notebook - Data before 2020-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:32:53 [INFO] notebook - Data before 2020-08-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:33:09 [INFO] notebook - Data before 2020-08-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:33:24 [INFO] notebook - Data before 2020-08-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:33:40 [INFO] notebook - Data before 2020-08-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:33:57 [INFO] notebook - Data before 2020-08-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:34:13 [INFO] notebook - Data before 2020-08-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:34:29 [INFO] notebook - Data before 2020-08-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:34:45 [INFO] notebook - Data before 2020-08-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:35:02 [INFO] notebook - Data before 2020-08-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:35:17 [INFO] notebook - Data before 2020-08-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:35:34 [INFO] notebook - Data before 2020-08-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:35:50 [INFO] notebook - Data before 2020-08-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:36:06 [INFO] notebook - Data before 2020-08-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:36:22 [INFO] notebook - Data before 2020-08-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:36:39 [INFO] notebook - Data before 2020-08-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:36:55 [INFO] notebook - Data before 2020-08-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:37:11 [INFO] notebook - Data before 2020-08-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:37:27 [INFO] notebook - Data before 2020-08-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:37:43 [INFO] notebook - Data before 2020-08-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:37:59 [INFO] notebook - Data before 2020-09-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:38:15 [INFO] notebook - Data before 2020-09-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:38:31 [INFO] notebook - Data before 2020-09-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:38:48 [INFO] notebook - Data before 2020-09-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:39:04 [INFO] notebook - Data before 2020-09-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:39:20 [INFO] notebook - Data before 2020-09-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:39:36 [INFO] notebook - Data before 2020-09-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:39:52 [INFO] notebook - Data before 2020-09-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:40:09 [INFO] notebook - Data before 2020-09-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:40:25 [INFO] notebook - Data before 2020-09-10T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 00:40:42 [INFO] notebook - Data before 2020-09-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:40:58 [INFO] notebook - Data before 2020-09-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:41:14 [INFO] notebook - Data before 2020-09-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:41:30 [INFO] notebook - Data before 2020-09-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:41:47 [INFO] notebook - Data before 2020-09-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:42:03 [INFO] notebook - Data before 2020-09-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:42:20 [INFO] notebook - Data before 2020-09-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:42:38 [INFO] notebook - Data before 2020-09-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:42:54 [INFO] notebook - Data before 2020-09-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:43:10 [INFO] notebook - Data before 2020-09-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:43:26 [INFO] notebook - Data before 2020-09-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:43:43 [INFO] notebook - Data before 2020-09-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:44:01 [INFO] notebook - Data before 2020-09-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:44:17 [INFO] notebook - Data before 2020-09-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:44:34 [INFO] notebook - Data before 2020-09-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:44:50 [INFO] notebook - Data before 2020-09-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:45:06 [INFO] notebook - Data before 2020-09-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:45:23 [INFO] notebook - Data before 2020-09-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:45:39 [INFO] notebook - Data before 2020-09-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:45:56 [INFO] notebook - Data before 2020-09-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:46:13 [INFO] notebook - Data before 2020-10-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:46:30 [INFO] notebook - Data before 2020-10-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:46:46 [INFO] notebook - Data before 2020-10-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:47:02 [INFO] notebook - Data before 2020-10-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:47:19 [INFO] notebook - Data before 2020-10-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:47:36 [INFO] notebook - Data before 2020-10-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:47:53 [INFO] notebook - Data before 2020-10-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:48:09 [INFO] notebook - Data before 2020-10-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:48:26 [INFO] notebook - Data before 2020-10-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:48:42 [INFO] notebook - Data before 2020-10-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:48:59 [INFO] notebook - Data before 2020-10-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:49:16 [INFO] notebook - Data before 2020-10-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:49:33 [INFO] notebook - Data before 2020-10-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:49:49 [INFO] notebook - Data before 2020-10-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:50:06 [INFO] notebook - Data before 2020-10-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:50:24 [INFO] notebook - Data before 2020-10-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:50:40 [INFO] notebook - Data before 2020-10-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:50:56 [INFO] notebook - Data before 2020-10-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:51:14 [INFO] notebook - Data before 2020-10-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:51:30 [INFO] notebook - Data before 2020-10-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:51:47 [INFO] notebook - Data before 2020-10-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:52:04 [INFO] notebook - Data before 2020-10-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:52:21 [INFO] notebook - Data before 2020-10-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:52:38 [INFO] notebook - Data before 2020-10-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:52:55 [INFO] notebook - Data before 2020-10-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:53:11 [INFO] notebook - Data before 2020-10-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:53:28 [INFO] notebook - Data before 2020-10-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:53:45 [INFO] notebook - Data before 2020-10-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:54:03 [INFO] notebook - Data before 2020-10-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:54:20 [INFO] notebook - Data before 2020-10-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:54:36 [INFO] notebook - Data before 2020-10-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 00:54:53 [INFO] notebook - Data before 2020-11-01T14:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:55:11 [INFO] notebook - Data before 2020-11-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:55:28 [INFO] notebook - Data before 2020-11-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:55:45 [INFO] notebook - Data before 2020-11-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:56:02 [INFO] notebook - Data before 2020-11-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:56:19 [INFO] notebook - Data before 2020-11-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:56:36 [INFO] notebook - Data before 2020-11-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:56:53 [INFO] notebook - Data before 2020-11-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:57:10 [INFO] notebook - Data before 2020-11-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:57:29 [INFO] notebook - Data before 2020-11-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:57:46 [INFO] notebook - Data before 2020-11-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:58:03 [INFO] notebook - Data before 2020-11-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:58:21 [INFO] notebook - Data before 2020-11-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:58:38 [INFO] notebook - Data before 2020-11-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:58:55 [INFO] notebook - Data before 2020-11-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:59:13 [INFO] notebook - Data before 2020-11-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:59:30 [INFO] notebook - Data before 2020-11-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 00:59:47 [INFO] notebook - Data before 2020-11-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:00:05 [INFO] notebook - Data before 2020-11-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:00:22 [INFO] notebook - Data before 2020-11-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:00:39 [INFO] notebook - Data before 2020-11-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:00:56 [INFO] notebook - Data before 2020-11-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:01:14 [INFO] notebook - Data before 2020-11-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:01:31 [INFO] notebook - Data before 2020-11-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:01:48 [INFO] notebook - Data before 2020-11-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:02:05 [INFO] notebook - Data before 2020-11-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:02:22 [INFO] notebook - Data before 2020-11-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:02:39 [INFO] notebook - Data before 2020-11-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:02:56 [INFO] notebook - Data before 2020-11-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:03:14 [INFO] notebook - Data before 2020-11-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:03:31 [INFO] notebook - Data before 2020-12-01T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 01:03:48 [INFO] notebook - Data before 2020-12-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:04:06 [INFO] notebook - Data before 2020-12-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:04:24 [INFO] notebook - Data before 2020-12-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:04:41 [INFO] notebook - Data before 2020-12-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:04:58 [INFO] notebook - Data before 2020-12-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:05:16 [INFO] notebook - Data before 2020-12-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:05:33 [INFO] notebook - Data before 2020-12-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:05:51 [INFO] notebook - Data before 2020-12-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:06:09 [INFO] notebook - Data before 2020-12-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:06:27 [INFO] notebook - Data before 2020-12-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:06:45 [INFO] notebook - Data before 2020-12-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:07:02 [INFO] notebook - Data before 2020-12-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:07:21 [INFO] notebook - Data before 2020-12-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:07:39 [INFO] notebook - Data before 2020-12-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:07:58 [INFO] notebook - Data before 2020-12-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:08:16 [INFO] notebook - Data before 2020-12-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:08:34 [INFO] notebook - Data before 2020-12-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:08:52 [INFO] notebook - Data before 2020-12-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:09:10 [INFO] notebook - Data before 2020-12-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:09:29 [INFO] notebook - Data before 2020-12-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:09:47 [INFO] notebook - Data before 2020-12-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:10:05 [INFO] notebook - Data before 2020-12-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:10:23 [INFO] notebook - Data before 2020-12-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:10:40 [INFO] notebook - Data before 2020-12-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:10:57 [INFO] notebook - Data before 2020-12-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:11:15 [INFO] notebook - Data before 2020-12-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:11:32 [INFO] notebook - Data before 2020-12-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:11:50 [INFO] notebook - Data before 2020-12-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:12:08 [INFO] notebook - Data before 2020-12-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:12:27 [INFO] notebook - Data before 2020-12-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:12:45 [INFO] notebook - Data before 2021-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:13:02 [INFO] notebook - Data before 2021-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:13:20 [INFO] notebook - Data before 2021-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:13:38 [INFO] notebook - Data before 2021-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:13:56 [INFO] notebook - Data before 2021-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:14:14 [INFO] notebook - Data before 2021-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:14:32 [INFO] notebook - Data before 2021-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:14:50 [INFO] notebook - Data before 2021-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:15:07 [INFO] notebook - Data before 2021-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:15:25 [INFO] notebook - Data before 2021-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:15:43 [INFO] notebook - Data before 2021-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:16:01 [INFO] notebook - Data before 2021-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:16:19 [INFO] notebook - Data before 2021-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:16:37 [INFO] notebook - Data before 2021-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:16:55 [INFO] notebook - Data before 2021-01-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:17:13 [INFO] notebook - Data before 2021-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:17:31 [INFO] notebook - Data before 2021-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:17:49 [INFO] notebook - Data before 2021-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:18:07 [INFO] notebook - Data before 2021-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:18:25 [INFO] notebook - Data before 2021-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:18:43 [INFO] notebook - Data before 2021-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:19:01 [INFO] notebook - Data before 2021-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:19:19 [INFO] notebook - Data before 2021-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:19:37 [INFO] notebook - Data before 2021-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:19:55 [INFO] notebook - Data before 2021-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:20:13 [INFO] notebook - Data before 2021-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:20:31 [INFO] notebook - Data before 2021-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:20:50 [INFO] notebook - Data before 2021-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:21:08 [INFO] notebook - Data before 2021-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:21:26 [INFO] notebook - Data before 2021-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:21:44 [INFO] notebook - Data before 2021-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:22:02 [INFO] notebook - Data before 2021-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:22:20 [INFO] notebook - Data before 2021-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:22:38 [INFO] notebook - Data before 2021-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:22:57 [INFO] notebook - Data before 2021-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:23:15 [INFO] notebook - Data before 2021-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:23:33 [INFO] notebook - Data before 2021-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:23:51 [INFO] notebook - Data before 2021-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:24:09 [INFO] notebook - Data before 2021-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:24:27 [INFO] notebook - Data before 2021-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:24:46 [INFO] notebook - Data before 2021-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:25:05 [INFO] notebook - Data before 2021-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:25:23 [INFO] notebook - Data before 2021-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:25:42 [INFO] notebook - Data before 2021-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:25:59 [INFO] notebook - Data before 2021-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:26:17 [INFO] notebook - Data before 2021-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:26:36 [INFO] notebook - Data before 2021-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:26:54 [INFO] notebook - Data before 2021-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:27:13 [INFO] notebook - Data before 2021-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:27:33 [INFO] notebook - Data before 2021-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:27:52 [INFO] notebook - Data before 2021-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:28:09 [INFO] notebook - Data before 2021-02-21T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 01:28:28 [INFO] notebook - Data before 2021-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:28:47 [INFO] notebook - Data before 2021-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:29:06 [INFO] notebook - Data before 2021-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:29:24 [INFO] notebook - Data before 2021-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:29:43 [INFO] notebook - Data before 2021-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:30:01 [INFO] notebook - Data before 2021-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:30:19 [INFO] notebook - Data before 2021-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:30:37 [INFO] notebook - Data before 2021-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:30:56 [INFO] notebook - Data before 2021-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:31:15 [INFO] notebook - Data before 2021-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:31:34 [INFO] notebook - Data before 2021-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:31:53 [INFO] notebook - Data before 2021-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:32:11 [INFO] notebook - Data before 2021-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:32:29 [INFO] notebook - Data before 2021-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:32:48 [INFO] notebook - Data before 2021-03-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:33:07 [INFO] notebook - Data before 2021-03-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:33:26 [INFO] notebook - Data before 2021-03-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:33:46 [INFO] notebook - Data before 2021-03-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:34:05 [INFO] notebook - Data before 2021-03-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:34:24 [INFO] notebook - Data before 2021-03-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 01:34:42 [INFO] notebook - Data before 2021-03-14T16:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:35:01 [INFO] notebook - Data before 2021-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:35:20 [INFO] notebook - Data before 2021-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:35:39 [INFO] notebook - Data before 2021-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:35:58 [INFO] notebook - Data before 2021-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:36:18 [INFO] notebook - Data before 2021-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:36:36 [INFO] notebook - Data before 2021-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:36:54 [INFO] notebook - Data before 2021-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:37:13 [INFO] notebook - Data before 2021-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:37:32 [INFO] notebook - Data before 2021-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:37:51 [INFO] notebook - Data before 2021-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:38:10 [INFO] notebook - Data before 2021-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:38:29 [INFO] notebook - Data before 2021-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:38:48 [INFO] notebook - Data before 2021-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:39:08 [INFO] notebook - Data before 2021-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:39:30 [INFO] notebook - Data before 2021-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:39:49 [INFO] notebook - Data before 2021-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:40:08 [INFO] notebook - Data before 2021-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:40:27 [INFO] notebook - Data before 2021-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:40:46 [INFO] notebook - Data before 2021-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:41:04 [INFO] notebook - Data before 2021-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:41:23 [INFO] notebook - Data before 2021-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:41:43 [INFO] notebook - Data before 2021-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:42:01 [INFO] notebook - Data before 2021-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:42:20 [INFO] notebook - Data before 2021-04-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:42:41 [INFO] notebook - Data before 2021-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:43:00 [INFO] notebook - Data before 2021-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:43:19 [INFO] notebook - Data before 2021-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:43:38 [INFO] notebook - Data before 2021-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:43:57 [INFO] notebook - Data before 2021-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:44:17 [INFO] notebook - Data before 2021-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:44:36 [INFO] notebook - Data before 2021-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:44:56 [INFO] notebook - Data before 2021-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:45:15 [INFO] notebook - Data before 2021-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:45:34 [INFO] notebook - Data before 2021-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:45:52 [INFO] notebook - Data before 2021-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:46:11 [INFO] notebook - Data before 2021-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:46:31 [INFO] notebook - Data before 2021-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:46:51 [INFO] notebook - Data before 2021-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:47:10 [INFO] notebook - Data before 2021-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:47:30 [INFO] notebook - Data before 2021-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:47:49 [INFO] notebook - Data before 2021-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:48:08 [INFO] notebook - Data before 2021-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:48:27 [INFO] notebook - Data before 2021-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:48:46 [INFO] notebook - Data before 2021-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:49:05 [INFO] notebook - Data before 2021-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:49:25 [INFO] notebook - Data before 2021-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:49:45 [INFO] notebook - Data before 2021-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:50:04 [INFO] notebook - Data before 2021-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:50:23 [INFO] notebook - Data before 2021-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:50:42 [INFO] notebook - Data before 2021-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:51:02 [INFO] notebook - Data before 2021-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:51:21 [INFO] notebook - Data before 2021-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:51:41 [INFO] notebook - Data before 2021-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:52:01 [INFO] notebook - Data before 2021-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:52:19 [INFO] notebook - Data before 2021-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:52:39 [INFO] notebook - Data before 2021-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:52:59 [INFO] notebook - Data before 2021-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:53:19 [INFO] notebook - Data before 2021-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:53:39 [INFO] notebook - Data before 2021-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:53:59 [INFO] notebook - Data before 2021-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:54:19 [INFO] notebook - Data before 2021-05-14T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 01:54:38 [INFO] notebook - Data before 2021-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:54:58 [INFO] notebook - Data before 2021-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:55:18 [INFO] notebook - Data before 2021-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:55:37 [INFO] notebook - Data before 2021-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:55:57 [INFO] notebook - Data before 2021-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:56:17 [INFO] notebook - Data before 2021-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:56:37 [INFO] notebook - Data before 2021-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:56:56 [INFO] notebook - Data before 2021-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:57:16 [INFO] notebook - Data before 2021-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:57:37 [INFO] notebook - Data before 2021-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:57:58 [INFO] notebook - Data before 2021-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:58:17 [INFO] notebook - Data before 2021-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:58:37 [INFO] notebook - Data before 2021-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:58:57 [INFO] notebook - Data before 2021-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:59:17 [INFO] notebook - Data before 2021-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:59:37 [INFO] notebook - Data before 2021-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 01:59:57 [INFO] notebook - Data before 2021-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:00:17 [INFO] notebook - Data before 2021-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:00:37 [INFO] notebook - Data before 2021-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:00:57 [INFO] notebook - Data before 2021-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:01:17 [INFO] notebook - Data before 2021-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:01:37 [INFO] notebook - Data before 2021-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:01:56 [INFO] notebook - Data before 2021-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:02:16 [INFO] notebook - Data before 2021-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:02:36 [INFO] notebook - Data before 2021-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:02:56 [INFO] notebook - Data before 2021-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:03:17 [INFO] notebook - Data before 2021-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:03:37 [INFO] notebook - Data before 2021-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:03:57 [INFO] notebook - Data before 2021-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:04:17 [INFO] notebook - Data before 2021-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:04:37 [INFO] notebook - Data before 2021-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:04:57 [INFO] notebook - Data before 2021-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:05:18 [INFO] notebook - Data before 2021-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:05:38 [INFO] notebook - Data before 2021-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:05:58 [INFO] notebook - Data before 2021-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:06:19 [INFO] notebook - Data before 2021-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:06:39 [INFO] notebook - Data before 2021-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:06:59 [INFO] notebook - Data before 2021-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:07:19 [INFO] notebook - Data before 2021-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:07:40 [INFO] notebook - Data before 2021-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:08:00 [INFO] notebook - Data before 2021-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:08:20 [INFO] notebook - Data before 2021-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:08:40 [INFO] notebook - Data before 2021-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:09:00 [INFO] notebook - Data before 2021-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:09:20 [INFO] notebook - Data before 2021-06-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:09:40 [INFO] notebook - Data before 2021-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:10:01 [INFO] notebook - Data before 2021-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:10:21 [INFO] notebook - Data before 2021-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:10:41 [INFO] notebook - Data before 2021-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:11:01 [INFO] notebook - Data before 2021-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:11:21 [INFO] notebook - Data before 2021-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:11:41 [INFO] notebook - Data before 2021-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:12:02 [INFO] notebook - Data before 2021-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:12:23 [INFO] notebook - Data before 2021-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:12:44 [INFO] notebook - Data before 2021-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:13:05 [INFO] notebook - Data before 2021-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:13:25 [INFO] notebook - Data before 2021-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:13:45 [INFO] notebook - Data before 2021-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:14:06 [INFO] notebook - Data before 2021-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:14:27 [INFO] notebook - Data before 2021-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:14:47 [INFO] notebook - Data before 2021-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:15:07 [INFO] notebook - Data before 2021-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:15:28 [INFO] notebook - Data before 2021-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:15:48 [INFO] notebook - Data before 2021-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:16:09 [INFO] notebook - Data before 2021-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:16:29 [INFO] notebook - Data before 2021-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:16:49 [INFO] notebook - Data before 2021-07-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:17:10 [INFO] notebook - Data before 2021-07-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:17:31 [INFO] notebook - Data before 2021-07-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:17:52 [INFO] notebook - Data before 2021-07-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:18:12 [INFO] notebook - Data before 2021-07-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:18:32 [INFO] notebook - Data before 2021-07-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:18:53 [INFO] notebook - Data before 2021-07-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:19:14 [INFO] notebook - Data before 2021-07-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:19:34 [INFO] notebook - Data before 2021-07-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:19:55 [INFO] notebook - Data before 2021-07-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:20:16 [INFO] notebook - Data before 2021-07-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:20:36 [INFO] notebook - Data before 2021-07-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:20:57 [INFO] notebook - Data before 2021-08-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:21:18 [INFO] notebook - Data before 2021-08-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:21:39 [INFO] notebook - Data before 2021-08-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:21:59 [INFO] notebook - Data before 2021-08-04T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 02:22:20 [INFO] notebook - Data before 2021-08-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:22:41 [INFO] notebook - Data before 2021-08-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:23:02 [INFO] notebook - Data before 2021-08-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:23:22 [INFO] notebook - Data before 2021-08-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:23:43 [INFO] notebook - Data before 2021-08-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:24:04 [INFO] notebook - Data before 2021-08-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:24:25 [INFO] notebook - Data before 2021-08-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:24:46 [INFO] notebook - Data before 2021-08-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:25:07 [INFO] notebook - Data before 2021-08-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:25:28 [INFO] notebook - Data before 2021-08-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:25:49 [INFO] notebook - Data before 2021-08-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:26:11 [INFO] notebook - Data before 2021-08-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:26:32 [INFO] notebook - Data before 2021-08-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:26:53 [INFO] notebook - Data before 2021-08-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:27:14 [INFO] notebook - Data before 2021-08-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:27:38 [INFO] notebook - Data before 2021-08-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:27:58 [INFO] notebook - Data before 2021-08-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:28:19 [INFO] notebook - Data before 2021-08-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:28:41 [INFO] notebook - Data before 2021-08-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:29:02 [INFO] notebook - Data before 2021-08-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:29:24 [INFO] notebook - Data before 2021-08-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:29:44 [INFO] notebook - Data before 2021-08-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:30:05 [INFO] notebook - Data before 2021-08-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:30:26 [INFO] notebook - Data before 2021-08-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:30:47 [INFO] notebook - Data before 2021-08-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:31:08 [INFO] notebook - Data before 2021-08-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:31:29 [INFO] notebook - Data before 2021-08-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:31:50 [INFO] notebook - Data before 2021-09-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:32:11 [INFO] notebook - Data before 2021-09-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:32:32 [INFO] notebook - Data before 2021-09-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:32:53 [INFO] notebook - Data before 2021-09-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:33:14 [INFO] notebook - Data before 2021-09-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:33:35 [INFO] notebook - Data before 2021-09-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:33:56 [INFO] notebook - Data before 2021-09-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:34:18 [INFO] notebook - Data before 2021-09-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:34:39 [INFO] notebook - Data before 2021-09-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:35:01 [INFO] notebook - Data before 2021-09-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:35:22 [INFO] notebook - Data before 2021-09-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:35:43 [INFO] notebook - Data before 2021-09-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:36:04 [INFO] notebook - Data before 2021-09-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:36:26 [INFO] notebook - Data before 2021-09-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:36:47 [INFO] notebook - Data before 2021-09-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:37:09 [INFO] notebook - Data before 2021-09-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:37:30 [INFO] notebook - Data before 2021-09-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:37:51 [INFO] notebook - Data before 2021-09-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:38:12 [INFO] notebook - Data before 2021-09-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:38:33 [INFO] notebook - Data before 2021-09-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:38:55 [INFO] notebook - Data before 2021-09-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:39:16 [INFO] notebook - Data before 2021-09-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:39:38 [INFO] notebook - Data before 2021-09-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:39:59 [INFO] notebook - Data before 2021-09-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:40:20 [INFO] notebook - Data before 2021-09-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:40:41 [INFO] notebook - Data before 2021-09-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:41:03 [INFO] notebook - Data before 2021-09-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:41:24 [INFO] notebook - Data before 2021-09-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:41:46 [INFO] notebook - Data before 2021-09-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:42:07 [INFO] notebook - Data before 2021-09-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:42:27 [INFO] notebook - Data before 2021-10-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:42:45 [INFO] notebook - Data before 2021-10-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:43:06 [INFO] notebook - Data before 2021-10-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:43:28 [INFO] notebook - Data before 2021-10-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:43:49 [INFO] notebook - Data before 2021-10-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:44:11 [INFO] notebook - Data before 2021-10-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:44:33 [INFO] notebook - Data before 2021-10-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:44:54 [INFO] notebook - Data before 2021-10-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:45:15 [INFO] notebook - Data before 2021-10-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:45:36 [INFO] notebook - Data before 2021-10-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:45:58 [INFO] notebook - Data before 2021-10-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:46:19 [INFO] notebook - Data before 2021-10-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:46:41 [INFO] notebook - Data before 2021-10-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:47:02 [INFO] notebook - Data before 2021-10-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:47:24 [INFO] notebook - Data before 2021-10-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:47:45 [INFO] notebook - Data before 2021-10-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:48:07 [INFO] notebook - Data before 2021-10-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:48:28 [INFO] notebook - Data before 2021-10-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:48:50 [INFO] notebook - Data before 2021-10-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:49:12 [INFO] notebook - Data before 2021-10-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:49:34 [INFO] notebook - Data before 2021-10-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:49:56 [INFO] notebook - Data before 2021-10-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:50:18 [INFO] notebook - Data before 2021-10-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:50:39 [INFO] notebook - Data before 2021-10-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:51:01 [INFO] notebook - Data before 2021-10-25T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 02:51:23 [INFO] notebook - Data before 2021-10-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:51:45 [INFO] notebook - Data before 2021-10-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:52:07 [INFO] notebook - Data before 2021-10-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:52:29 [INFO] notebook - Data before 2021-10-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:52:50 [INFO] notebook - Data before 2021-10-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:53:12 [INFO] notebook - Data before 2021-10-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:53:34 [INFO] notebook - Data before 2021-11-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:53:57 [INFO] notebook - Data before 2021-11-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:54:18 [INFO] notebook - Data before 2021-11-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:54:41 [INFO] notebook - Data before 2021-11-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:55:03 [INFO] notebook - Data before 2021-11-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:55:24 [INFO] notebook - Data before 2021-11-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 02:55:46 [INFO] notebook - Data before 2021-11-07T14:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:56:10 [INFO] notebook - Data before 2021-11-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:56:32 [INFO] notebook - Data before 2021-11-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:56:54 [INFO] notebook - Data before 2021-11-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:57:17 [INFO] notebook - Data before 2021-11-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:57:39 [INFO] notebook - Data before 2021-11-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:58:01 [INFO] notebook - Data before 2021-11-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:58:23 [INFO] notebook - Data before 2021-11-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:58:46 [INFO] notebook - Data before 2021-11-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:59:08 [INFO] notebook - Data before 2021-11-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:59:30 [INFO] notebook - Data before 2021-11-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 02:59:52 [INFO] notebook - Data before 2021-11-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:00:15 [INFO] notebook - Data before 2021-11-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:00:37 [INFO] notebook - Data before 2021-11-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:00:59 [INFO] notebook - Data before 2021-11-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:01:21 [INFO] notebook - Data before 2021-11-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:01:44 [INFO] notebook - Data before 2021-11-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:02:06 [INFO] notebook - Data before 2021-11-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:02:27 [INFO] notebook - Data before 2021-11-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:02:50 [INFO] notebook - Data before 2021-11-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:03:12 [INFO] notebook - Data before 2021-11-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:03:34 [INFO] notebook - Data before 2021-11-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:03:56 [INFO] notebook - Data before 2021-11-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:04:19 [INFO] notebook - Data before 2021-11-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:04:41 [INFO] notebook - Data before 2021-12-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:05:03 [INFO] notebook - Data before 2021-12-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:05:26 [INFO] notebook - Data before 2021-12-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:05:48 [INFO] notebook - Data before 2021-12-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:06:11 [INFO] notebook - Data before 2021-12-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:06:34 [INFO] notebook - Data before 2021-12-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:06:57 [INFO] notebook - Data before 2021-12-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:07:20 [INFO] notebook - Data before 2021-12-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:07:43 [INFO] notebook - Data before 2021-12-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:08:05 [INFO] notebook - Data before 2021-12-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:08:27 [INFO] notebook - Data before 2021-12-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:08:50 [INFO] notebook - Data before 2021-12-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:09:13 [INFO] notebook - Data before 2021-12-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:09:35 [INFO] notebook - Data before 2021-12-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:09:58 [INFO] notebook - Data before 2021-12-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:10:20 [INFO] notebook - Data before 2021-12-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:10:43 [INFO] notebook - Data before 2021-12-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:11:05 [INFO] notebook - Data before 2021-12-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:11:28 [INFO] notebook - Data before 2021-12-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:11:51 [INFO] notebook - Data before 2021-12-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:12:15 [INFO] notebook - Data before 2021-12-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:12:40 [INFO] notebook - Data before 2021-12-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:13:03 [INFO] notebook - Data before 2021-12-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:13:26 [INFO] notebook - Data before 2021-12-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:13:50 [INFO] notebook - Data before 2021-12-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:14:12 [INFO] notebook - Data before 2021-12-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:14:36 [INFO] notebook - Data before 2021-12-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:14:59 [INFO] notebook - Data before 2021-12-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:15:23 [INFO] notebook - Data before 2021-12-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:15:46 [INFO] notebook - Data before 2021-12-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:16:09 [INFO] notebook - Data before 2021-12-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:16:32 [INFO] notebook - Data before 2022-01-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:16:59 [INFO] notebook - Data before 2022-01-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:17:20 [INFO] notebook - Data before 2022-01-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:17:41 [INFO] notebook - Data before 2022-01-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:18:01 [INFO] notebook - Data before 2022-01-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:18:20 [INFO] notebook - Data before 2022-01-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:18:40 [INFO] notebook - Data before 2022-01-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:19:00 [INFO] notebook - Data before 2022-01-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:19:20 [INFO] notebook - Data before 2022-01-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:19:40 [INFO] notebook - Data before 2022-01-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:20:00 [INFO] notebook - Data before 2022-01-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:20:20 [INFO] notebook - Data before 2022-01-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:20:40 [INFO] notebook - Data before 2022-01-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:20:59 [INFO] notebook - Data before 2022-01-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:21:19 [INFO] notebook - Data before 2022-01-15T15:59:00-05:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 03:21:39 [INFO] notebook - Data before 2022-01-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:21:59 [INFO] notebook - Data before 2022-01-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:22:19 [INFO] notebook - Data before 2022-01-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:22:40 [INFO] notebook - Data before 2022-01-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:23:03 [INFO] notebook - Data before 2022-01-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:23:24 [INFO] notebook - Data before 2022-01-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:23:44 [INFO] notebook - Data before 2022-01-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:24:03 [INFO] notebook - Data before 2022-01-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:24:23 [INFO] notebook - Data before 2022-01-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:24:43 [INFO] notebook - Data before 2022-01-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:25:04 [INFO] notebook - Data before 2022-01-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:25:24 [INFO] notebook - Data before 2022-01-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:25:44 [INFO] notebook - Data before 2022-01-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:26:03 [INFO] notebook - Data before 2022-01-29T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:26:23 [INFO] notebook - Data before 2022-01-30T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:26:43 [INFO] notebook - Data before 2022-01-31T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:27:03 [INFO] notebook - Data before 2022-02-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:27:25 [INFO] notebook - Data before 2022-02-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:27:46 [INFO] notebook - Data before 2022-02-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:28:06 [INFO] notebook - Data before 2022-02-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:28:26 [INFO] notebook - Data before 2022-02-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:28:47 [INFO] notebook - Data before 2022-02-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:29:07 [INFO] notebook - Data before 2022-02-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:29:27 [INFO] notebook - Data before 2022-02-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:29:47 [INFO] notebook - Data before 2022-02-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:30:08 [INFO] notebook - Data before 2022-02-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:30:28 [INFO] notebook - Data before 2022-02-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:30:48 [INFO] notebook - Data before 2022-02-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:31:08 [INFO] notebook - Data before 2022-02-13T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:31:28 [INFO] notebook - Data before 2022-02-14T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:31:48 [INFO] notebook - Data before 2022-02-15T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:32:09 [INFO] notebook - Data before 2022-02-16T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:32:29 [INFO] notebook - Data before 2022-02-17T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:32:50 [INFO] notebook - Data before 2022-02-18T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:33:10 [INFO] notebook - Data before 2022-02-19T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:33:30 [INFO] notebook - Data before 2022-02-20T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:33:51 [INFO] notebook - Data before 2022-02-21T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:34:11 [INFO] notebook - Data before 2022-02-22T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:34:31 [INFO] notebook - Data before 2022-02-23T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:34:52 [INFO] notebook - Data before 2022-02-24T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:35:12 [INFO] notebook - Data before 2022-02-25T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:35:33 [INFO] notebook - Data before 2022-02-26T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:35:53 [INFO] notebook - Data before 2022-02-27T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:36:14 [INFO] notebook - Data before 2022-02-28T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:36:34 [INFO] notebook - Data before 2022-03-01T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:36:54 [INFO] notebook - Data before 2022-03-02T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:37:15 [INFO] notebook - Data before 2022-03-03T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:37:36 [INFO] notebook - Data before 2022-03-04T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:37:56 [INFO] notebook - Data before 2022-03-05T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:38:16 [INFO] notebook - Data before 2022-03-06T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:38:37 [INFO] notebook - Data before 2022-03-07T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:38:57 [INFO] notebook - Data before 2022-03-08T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:39:18 [INFO] notebook - Data before 2022-03-09T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:39:39 [INFO] notebook - Data before 2022-03-10T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:39:59 [INFO] notebook - Data before 2022-03-11T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:40:20 [INFO] notebook - Data before 2022-03-12T15:59:00-05:00 is successfully fetched\n",
      "2022-07-21 03:40:40 [INFO] notebook - Data before 2022-03-13T16:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:41:01 [INFO] notebook - Data before 2022-03-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:41:21 [INFO] notebook - Data before 2022-03-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:41:42 [INFO] notebook - Data before 2022-03-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:42:03 [INFO] notebook - Data before 2022-03-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:42:26 [INFO] notebook - Data before 2022-03-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:42:46 [INFO] notebook - Data before 2022-03-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:43:07 [INFO] notebook - Data before 2022-03-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:43:28 [INFO] notebook - Data before 2022-03-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:43:49 [INFO] notebook - Data before 2022-03-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:44:09 [INFO] notebook - Data before 2022-03-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:44:30 [INFO] notebook - Data before 2022-03-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:44:51 [INFO] notebook - Data before 2022-03-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:45:12 [INFO] notebook - Data before 2022-03-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:45:33 [INFO] notebook - Data before 2022-03-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:45:54 [INFO] notebook - Data before 2022-03-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:46:16 [INFO] notebook - Data before 2022-03-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:46:36 [INFO] notebook - Data before 2022-03-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:46:58 [INFO] notebook - Data before 2022-03-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:47:19 [INFO] notebook - Data before 2022-04-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:47:39 [INFO] notebook - Data before 2022-04-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:47:59 [INFO] notebook - Data before 2022-04-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:48:21 [INFO] notebook - Data before 2022-04-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:48:42 [INFO] notebook - Data before 2022-04-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:49:03 [INFO] notebook - Data before 2022-04-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:49:24 [INFO] notebook - Data before 2022-04-07T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 03:49:45 [INFO] notebook - Data before 2022-04-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:50:05 [INFO] notebook - Data before 2022-04-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:50:26 [INFO] notebook - Data before 2022-04-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:50:47 [INFO] notebook - Data before 2022-04-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:51:08 [INFO] notebook - Data before 2022-04-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:51:29 [INFO] notebook - Data before 2022-04-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:51:49 [INFO] notebook - Data before 2022-04-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:52:10 [INFO] notebook - Data before 2022-04-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:52:31 [INFO] notebook - Data before 2022-04-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:52:51 [INFO] notebook - Data before 2022-04-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:53:12 [INFO] notebook - Data before 2022-04-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:53:33 [INFO] notebook - Data before 2022-04-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:53:54 [INFO] notebook - Data before 2022-04-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:54:15 [INFO] notebook - Data before 2022-04-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:54:37 [INFO] notebook - Data before 2022-04-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:54:59 [INFO] notebook - Data before 2022-04-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:55:20 [INFO] notebook - Data before 2022-04-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:55:41 [INFO] notebook - Data before 2022-04-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:56:03 [INFO] notebook - Data before 2022-04-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:56:24 [INFO] notebook - Data before 2022-04-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:56:45 [INFO] notebook - Data before 2022-04-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:57:06 [INFO] notebook - Data before 2022-04-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:57:29 [INFO] notebook - Data before 2022-04-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:57:49 [INFO] notebook - Data before 2022-05-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:58:11 [INFO] notebook - Data before 2022-05-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:58:32 [INFO] notebook - Data before 2022-05-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:58:54 [INFO] notebook - Data before 2022-05-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:59:14 [INFO] notebook - Data before 2022-05-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:59:36 [INFO] notebook - Data before 2022-05-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 03:59:58 [INFO] notebook - Data before 2022-05-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:00:19 [INFO] notebook - Data before 2022-05-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:00:40 [INFO] notebook - Data before 2022-05-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:01:01 [INFO] notebook - Data before 2022-05-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:01:23 [INFO] notebook - Data before 2022-05-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:01:45 [INFO] notebook - Data before 2022-05-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:02:06 [INFO] notebook - Data before 2022-05-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:02:27 [INFO] notebook - Data before 2022-05-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:02:48 [INFO] notebook - Data before 2022-05-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:03:10 [INFO] notebook - Data before 2022-05-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:03:31 [INFO] notebook - Data before 2022-05-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:03:53 [INFO] notebook - Data before 2022-05-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:04:15 [INFO] notebook - Data before 2022-05-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:04:37 [INFO] notebook - Data before 2022-05-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:04:58 [INFO] notebook - Data before 2022-05-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:05:19 [INFO] notebook - Data before 2022-05-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:05:42 [INFO] notebook - Data before 2022-05-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:06:06 [INFO] notebook - Data before 2022-05-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:06:27 [INFO] notebook - Data before 2022-05-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:06:49 [INFO] notebook - Data before 2022-05-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:07:11 [INFO] notebook - Data before 2022-05-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:07:33 [INFO] notebook - Data before 2022-05-28T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:07:55 [INFO] notebook - Data before 2022-05-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:08:18 [INFO] notebook - Data before 2022-05-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:08:40 [INFO] notebook - Data before 2022-05-31T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:09:02 [INFO] notebook - Data before 2022-06-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:09:24 [INFO] notebook - Data before 2022-06-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:09:47 [INFO] notebook - Data before 2022-06-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:10:09 [INFO] notebook - Data before 2022-06-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:10:31 [INFO] notebook - Data before 2022-06-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:10:53 [INFO] notebook - Data before 2022-06-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:11:15 [INFO] notebook - Data before 2022-06-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:11:37 [INFO] notebook - Data before 2022-06-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:11:59 [INFO] notebook - Data before 2022-06-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:12:21 [INFO] notebook - Data before 2022-06-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:12:44 [INFO] notebook - Data before 2022-06-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:13:05 [INFO] notebook - Data before 2022-06-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:13:28 [INFO] notebook - Data before 2022-06-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:13:49 [INFO] notebook - Data before 2022-06-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:14:11 [INFO] notebook - Data before 2022-06-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:14:33 [INFO] notebook - Data before 2022-06-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:14:55 [INFO] notebook - Data before 2022-06-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:15:17 [INFO] notebook - Data before 2022-06-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:15:38 [INFO] notebook - Data before 2022-06-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:15:59 [INFO] notebook - Data before 2022-06-20T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:16:21 [INFO] notebook - Data before 2022-06-21T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:16:44 [INFO] notebook - Data before 2022-06-22T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:17:06 [INFO] notebook - Data before 2022-06-23T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:17:28 [INFO] notebook - Data before 2022-06-24T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:17:50 [INFO] notebook - Data before 2022-06-25T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:18:11 [INFO] notebook - Data before 2022-06-26T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:18:34 [INFO] notebook - Data before 2022-06-27T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:18:57 [INFO] notebook - Data before 2022-06-28T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 04:19:19 [INFO] notebook - Data before 2022-06-29T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:19:41 [INFO] notebook - Data before 2022-06-30T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:20:03 [INFO] notebook - Data before 2022-07-01T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:20:24 [INFO] notebook - Data before 2022-07-02T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:20:46 [INFO] notebook - Data before 2022-07-03T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:21:07 [INFO] notebook - Data before 2022-07-04T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:21:29 [INFO] notebook - Data before 2022-07-05T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:21:51 [INFO] notebook - Data before 2022-07-06T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:22:13 [INFO] notebook - Data before 2022-07-07T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:22:36 [INFO] notebook - Data before 2022-07-08T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:22:57 [INFO] notebook - Data before 2022-07-09T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:23:19 [INFO] notebook - Data before 2022-07-10T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:23:41 [INFO] notebook - Data before 2022-07-11T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:24:03 [INFO] notebook - Data before 2022-07-12T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:24:26 [INFO] notebook - Data before 2022-07-13T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:24:48 [INFO] notebook - Data before 2022-07-14T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:25:10 [INFO] notebook - Data before 2022-07-15T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:25:34 [INFO] notebook - Data before 2022-07-16T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:25:56 [INFO] notebook - Data before 2022-07-17T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:26:19 [INFO] notebook - Data before 2022-07-18T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:26:42 [INFO] notebook - Data before 2022-07-19T15:59:00-04:00 is successfully fetched\n",
      "2022-07-21 04:27:08 [INFO] notebook - Data before 2022-07-20T15:59:00-04:00 is successfully fetched\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRETRAIN_START_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRETRAIN_END_DATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malpaca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcandle_time_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtechnical_indicator_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mINDICATORS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdrl_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstable_baselines3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mAPI_SECRET\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAPI_SECRET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m      \u001b[49m\u001b[43mAPI_BASE_URL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAPI_BASE_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m      \u001b[49m\u001b[43magent_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPPO_PARAMS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOTAL_TIMESTEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRETRAIN_CWD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbreak_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\code\\forex\\finrl\\finrl\\train.py:44\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(start_date, end_date, ticker_list, data_source, time_interval, technical_indicator_list, drl_lib, env, model_name, if_vix, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m dp \u001b[38;5;241m=\u001b[39m DataProcessor(data_source, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m data \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39mdownload_data(ticker_list, start_date, end_date, time_interval)\n\u001b[1;32m---> 44\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m data \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39madd_technical_indicator(data, technical_indicator_list)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_vix:\n",
      "File \u001b[1;32mc:\\code\\forex\\finrl\\finrl\\finrl_meta\\data_processor.py:46\u001b[0m, in \u001b[0;36mDataProcessor.clean_data\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, df) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m---> 46\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\code\\forex\\finrl\\finrl\\finrl_meta\\data_processors\\processor_alpaca.py:104\u001b[0m, in \u001b[0;36mAlpacaProcessor.clean_data\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    102\u001b[0m tic_df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mtic \u001b[38;5;241m==\u001b[39m tic]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tic_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 104\u001b[0m     tmp_df\u001b[38;5;241m.\u001b[39mloc[tic_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m tic_df\u001b[38;5;241m.\u001b[39miloc[i][\n\u001b[0;32m    105\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    106\u001b[0m     ]\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m#if the close price of the first row is NaN\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(tmp_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m#    print('The price of the first row for ticker ', tic, ' is NaN. ',\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m#          'It will filled with the first valid price.')\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexing.py:1682\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1683\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexing.py:2020\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2020\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\frame.py:9088\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9085\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9086\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[1;32m-> 9088\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9092\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9093\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   9094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   9095\u001b[0m     combined_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   9096\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9101\u001b[0m     \u001b[38;5;66;03m# combined_columns.equals check is necessary for preserving dtype\u001b[39;00m\n\u001b[0;32m   9102\u001b[0m     \u001b[38;5;66;03m#  in test_crosstab_normalize\u001b[39;00m\n\u001b[0;32m   9103\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreindex(combined_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:542\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_new_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator._get_new_axes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    611\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    615\u001b[0m     ]\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:613\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    611\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 613\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    615\u001b[0m     ]\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\_libs\\properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:668\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 668\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m \u001b[43m_concat_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _make_concat_multiindex(\n\u001b[0;32m    671\u001b[0m         indexes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    672\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:686\u001b[0m, in \u001b[0;36m_concat_indexes\u001b[1;34m(indexes)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concat_indexes\u001b[39m(indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m--> 686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5120\u001b[0m, in \u001b[0;36mIndex.append\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   5117\u001b[0m names \u001b[38;5;241m=\u001b[39m {obj\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m to_concat}\n\u001b[0;32m   5118\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m-> 5120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5134\u001b[0m, in \u001b[0;36mIndex._concat\u001b[1;34m(self, to_concat, name)\u001b[0m\n\u001b[0;32m   5131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_backward_compat_public_numeric_index \u001b[38;5;129;01mand\u001b[39;00m is_numeric:\n\u001b[0;32m   5132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(result, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m-> 5134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexes\\base.py:680\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    679\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*the Index constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 680\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    686\u001b[0m     values \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result\u001b[38;5;241m.\u001b[39m_values)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexes\\base.py:494\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m arr \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 494\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cast_data_without_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast_numeric_deprecated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7132\u001b[0m, in \u001b[0;36m_maybe_cast_data_without_dtype\u001b[1;34m(subarr, cast_numeric_deprecated)\u001b[0m\n\u001b[0;32m   7109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   7110\u001b[0m \u001b[38;5;124;03mIf we have an arraylike input but no passed dtype, try to infer\u001b[39;00m\n\u001b[0;32m   7111\u001b[0m \u001b[38;5;124;03ma supported dtype.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7121\u001b[0m \u001b[38;5;124;03mnp.ndarray or ExtensionArray\u001b[39;00m\n\u001b[0;32m   7122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   7124\u001b[0m result \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(\n\u001b[0;32m   7125\u001b[0m     subarr,\n\u001b[0;32m   7126\u001b[0m     convert_datetime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7130\u001b[0m     dtype_if_all_nat\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   7131\u001b[0m )\n\u001b[1;32m-> 7132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   7133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cast_numeric_deprecated:\n\u001b[0;32m   7134\u001b[0m         \u001b[38;5;66;03m# i.e. we started with a list, not an ndarray[object]\u001b[39;00m\n\u001b[0;32m   7135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(start_date = RETRAIN_START_DATE, \n",
    "      end_date = RETRAIN_END_DATE,\n",
    "      ticker_list = ticker_list, \n",
    "      data_source = 'alpaca',\n",
    "      time_interval= candle_time_interval, \n",
    "      technical_indicator_list= INDICATORS,\n",
    "      drl_lib='stable_baselines3', \n",
    "      env=env, \n",
    "      model_name=MODEL_NAME, \n",
    "      API_KEY = API_KEY, \n",
    "      API_SECRET = API_SECRET, \n",
    "      API_BASE_URL = API_BASE_URL,\n",
    "      agent_params=PPO_PARAMS,\n",
    "      total_timesteps=TOTAL_TIMESTEPS,\n",
    "      cwd=RETRAIN_CWD,\n",
    "      break_step=5e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIQN6Ggt7gXY"
   },
   "source": [
    "# Part 3: Deploy the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFoxkigg1zXa"
   },
   "source": [
    "## Setup Alpaca Paper trading environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LpkoZpYzfneS"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import threading\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "import alpaca_trade_api as tradeapi\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "class AlpacaPaperTrading():\n",
    "\n",
    "    def __init__(self,ticker_list, time_interval, drl_lib, agent, cwd, net_dim, \n",
    "                 state_dim, action_dim, API_KEY, API_SECRET, \n",
    "                 API_BASE_URL, tech_indicator_list, turbulence_thresh=30, \n",
    "                 max_stock=1e2, latency = None):\n",
    "        #load agent\n",
    "        self.drl_lib = drl_lib\n",
    "        if agent =='ppo':\n",
    "            if drl_lib == 'elegantrl':              \n",
    "                from elegantrl.agents import AgentPPO\n",
    "                from elegantrl.train.run import init_agent\n",
    "                from elegantrl.train.config import Arguments\n",
    "                #load agent\n",
    "                config = {'state_dim':state_dim,\n",
    "                            'action_dim':action_dim,}\n",
    "                args = Arguments(agent=AgentPPO, env=StockEnvEmpty(config))\n",
    "                args.cwd = cwd\n",
    "                args.net_dim = net_dim\n",
    "                # load agent\n",
    "                try:\n",
    "                    agent = init_agent(args, gpu_id = 0)\n",
    "                    self.act = agent.act\n",
    "                    self.device = agent.device\n",
    "                except BaseException:\n",
    "                    raise ValueError(\"Fail to load agent!\")\n",
    "                        \n",
    "            elif drl_lib == 'rllib':\n",
    "                from ray.rllib.agents import ppo\n",
    "                from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
    "                \n",
    "                config = ppo.DEFAULT_CONFIG.copy()\n",
    "                config['env'] = StockEnvEmpty\n",
    "                config[\"log_level\"] = \"WARN\"\n",
    "                config['env_config'] = {'state_dim':state_dim,\n",
    "                            'action_dim':action_dim,}\n",
    "                trainer = PPOTrainer(env=StockEnvEmpty, config=config)\n",
    "                trainer.restore(cwd)\n",
    "                try:\n",
    "                    trainer.restore(cwd)\n",
    "                    self.agent = trainer\n",
    "                    print(\"Restoring from checkpoint path\", cwd)\n",
    "                except:\n",
    "                    raise ValueError('Fail to load agent!')\n",
    "                    \n",
    "            elif drl_lib == 'stable_baselines3':\n",
    "                from stable_baselines3 import PPO\n",
    "                \n",
    "                try:\n",
    "                    #load agent\n",
    "                    self.model = PPO.load(cwd)\n",
    "                    print(\"Successfully load model\", cwd)\n",
    "                except:\n",
    "                    raise ValueError('Fail to load agent!')\n",
    "                    \n",
    "            else:\n",
    "                raise ValueError('The DRL library input is NOT supported yet. Please check your input.')\n",
    "               \n",
    "        else:\n",
    "            raise ValueError('Agent input is NOT supported yet.')\n",
    "            \n",
    "            \n",
    "            \n",
    "        #connect to Alpaca trading API\n",
    "        try:\n",
    "            self.alpaca = tradeapi.REST(API_KEY,API_SECRET,API_BASE_URL, 'v2')\n",
    "        except:\n",
    "            raise ValueError('Fail to connect Alpaca. Please check account info and internet connection.')\n",
    "        \n",
    "        #read trading time interval\n",
    "        if time_interval == '1s':\n",
    "            self.time_interval = 1\n",
    "        elif time_interval == '5s':\n",
    "            self.time_interval = 5\n",
    "        elif time_interval == '1Min':\n",
    "            self.time_interval = 60\n",
    "        elif time_interval == '5Min':\n",
    "            self.time_interval = 60 * 5\n",
    "        elif time_interval == '15Min':\n",
    "            self.time_interval = 60 * 15\n",
    "        else:\n",
    "            raise ValueError('Time interval input is NOT supported yet.')\n",
    "        \n",
    "        #read trading settings\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.turbulence_thresh = turbulence_thresh\n",
    "        self.max_stock = max_stock \n",
    "        \n",
    "        #initialize account\n",
    "        self.stocks = np.asarray([0] * len(ticker_list)) #stocks holding\n",
    "        self.stocks_cd = np.zeros_like(self.stocks) \n",
    "        self.cash = None #cash record \n",
    "        self.stocks_df = pd.DataFrame(self.stocks, columns=['stocks'], index = ticker_list)\n",
    "        self.asset_list = []\n",
    "        self.price = np.asarray([0] * len(ticker_list))\n",
    "        self.stockUniverse = ticker_list\n",
    "        self.turbulence_bool = 0\n",
    "        self.equities = []\n",
    "        \n",
    "    def test_latency(self, test_times = 10): \n",
    "        total_time = 0\n",
    "        for i in range(0, test_times):\n",
    "            time0 = time.time()\n",
    "            self.get_state()\n",
    "            time1 = time.time()\n",
    "            temp_time = time1 - time0\n",
    "            total_time += temp_time\n",
    "        latency = total_time/test_times\n",
    "        print('latency for data processing: ', latency)\n",
    "        return latency\n",
    "        \n",
    "    def run(self):\n",
    "        orders = self.alpaca.list_orders(status=\"open\")\n",
    "        for order in orders:\n",
    "          self.alpaca.cancel_order(order.id)\n",
    "    \n",
    "        # Wait for market to open.\n",
    "        print(\"Waiting for market to open...\")\n",
    "        tAMO = threading.Thread(target=self.awaitMarketOpen)\n",
    "        tAMO.start()\n",
    "        tAMO.join()\n",
    "        print(\"Market opened.\")\n",
    "        while True:\n",
    "\n",
    "          # Figure out when the market will close so we can prepare to sell beforehand.\n",
    "          clock = self.alpaca.get_clock()\n",
    "          closingTime = clock.next_close.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "          currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "          self.timeToClose = closingTime - currTime\n",
    "    \n",
    "          if(self.timeToClose < (60)):\n",
    "            # Close all positions when 1 minutes til market close.\n",
    "            print(\"Market closing soon. Stop trading.\")\n",
    "            #break\n",
    "            \n",
    "            # Close all positions when 1 minutes til market close.\n",
    "            print(\"Market closing soon.  Closing positions.\")\n",
    "    \n",
    "            positions = self.alpaca.list_positions()\n",
    "            for position in positions:\n",
    "              if(position.side == 'long'):\n",
    "                orderSide = 'sell'\n",
    "              else:\n",
    "                orderSide = 'buy'\n",
    "              qty = abs(int(float(position.qty)))\n",
    "              respSO = []\n",
    "              tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
    "              tSubmitOrder.start()\n",
    "              tSubmitOrder.join()\n",
    "    \n",
    "            # Run script again after market close for next trading day.\n",
    "            print(\"Sleeping until market close (15 minutes).\")\n",
    "            time.sleep(60 * 15)\n",
    "            \n",
    "          else:\n",
    "            trade = threading.Thread(target=self.trade)\n",
    "            trade.start()\n",
    "            trade.join()\n",
    "            last_equity = float(self.alpaca.get_account().last_equity)\n",
    "            cur_time = time.time()\n",
    "            self.equities.append([cur_time,last_equity])\n",
    "            time.sleep(self.time_interval)\n",
    "            \n",
    "    def awaitMarketOpen(self):\n",
    "        isOpen = self.alpaca.get_clock().is_open\n",
    "        while(not isOpen):\n",
    "          clock = self.alpaca.get_clock()\n",
    "          openingTime = clock.next_open.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "          currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "          timeToOpen = int((openingTime - currTime) / 60)\n",
    "          print(str(timeToOpen) + \" minutes til market open.\")\n",
    "          time.sleep(60)\n",
    "          isOpen = self.alpaca.get_clock().is_open\n",
    "    \n",
    "    def trade(self):\n",
    "        state = self.get_state()\n",
    "        \n",
    "        if self.drl_lib == 'elegantrl':\n",
    "            with torch.no_grad():\n",
    "                s_tensor = torch.as_tensor((state,), device=self.device)\n",
    "                a_tensor = self.act(s_tensor)  \n",
    "                action = a_tensor.detach().cpu().numpy()[0]  \n",
    "                \n",
    "            action = (action * self.max_stock).astype(int)\n",
    "            \n",
    "        elif self.drl_lib == 'rllib':\n",
    "            action = self.agent.compute_single_action(state)\n",
    "        \n",
    "        elif self.drl_lib == 'stable_baselines3':\n",
    "            action = self.model.predict(state)[0]\n",
    "            print(\"action\", action)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('The DRL library input is NOT supported yet. Please check your input.')\n",
    "        \n",
    "        self.stocks_cd += 1\n",
    "        if self.turbulence_bool == 0:\n",
    "            \n",
    "#             print('turbulence_bool: ', self.turbulence_bool)\n",
    "            \n",
    "            \n",
    "            \n",
    "            min_action = 0  # stock_cd\n",
    "            \n",
    "#             print('min_action: ', min_action)\n",
    "#             print('np.where(action < -min_action): ', np.where(action < -min_action))\n",
    "#             print('np.where(action < -min_action)[0]: ', np.where(action < -min_action)[0])\n",
    "            \n",
    "            for index in np.where(action < -min_action)[0]:  # sell_index:\n",
    "                \n",
    "#                 print('sell: ')\n",
    "#                 print('index: ', index)\n",
    "#                 print('self.stocks[index]: ', self.stocks[index])\n",
    "                \n",
    "                sell_num_shares = min(self.stocks[index], -action[index])\n",
    "                qty =  abs(int(sell_num_shares))\n",
    "                respSO = []\n",
    "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'sell', respSO))\n",
    "                tSubmitOrder.start()\n",
    "                tSubmitOrder.join()\n",
    "                self.cash = float(self.alpaca.get_account().cash)\n",
    "                self.stocks_cd[index] = 0\n",
    "\n",
    "            for index in np.where(action > min_action)[0]:  # buy_index:\n",
    "                \n",
    "#                 print('buy: ')\n",
    "#                 print('index: ', index)\n",
    "#                 print('self.stocks[index]: ', self.stocks[index])\n",
    "                \n",
    "                if self.cash < 0:\n",
    "                    tmp_cash = 0\n",
    "                else:\n",
    "                    tmp_cash = self.cash\n",
    "                buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n",
    "                qty = abs(int(buy_num_shares))\n",
    "                respSO = []\n",
    "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'buy', respSO))\n",
    "                tSubmitOrder.start()\n",
    "                tSubmitOrder.join()\n",
    "                self.cash = float(self.alpaca.get_account().cash)\n",
    "                self.stocks_cd[index] = 0\n",
    "                \n",
    "        else:  # sell all when turbulence\n",
    "            positions = self.alpaca.list_positions()\n",
    "            for position in positions:\n",
    "                if(position.side == 'long'):\n",
    "                    orderSide = 'sell'\n",
    "                else:\n",
    "                    orderSide = 'buy'\n",
    "                qty = abs(int(float(position.qty)))\n",
    "                respSO = []\n",
    "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
    "                tSubmitOrder.start()\n",
    "                tSubmitOrder.join()\n",
    "            \n",
    "            self.stocks_cd[:] = 0\n",
    "            \n",
    "    \n",
    "    def get_state(self):\n",
    "        alpaca = AlpacaProcessor(api=self.alpaca)\n",
    "        price, tech, turbulence = alpaca.fetch_latest_data(ticker_list = self.stockUniverse, time_interval=candle_time_interval,\n",
    "                                                     tech_indicator_list=self.tech_indicator_list)\n",
    "        turbulence_bool = 1 if turbulence >= self.turbulence_thresh else 0\n",
    "        \n",
    "        turbulence = (self.sigmoid_sign(turbulence, self.turbulence_thresh) * 2 ** -5).astype(np.float32)\n",
    "        \n",
    "        tech = tech * 2 ** -7\n",
    "        positions = self.alpaca.list_positions()\n",
    "        stocks = [0] * len(self.stockUniverse)\n",
    "        for position in positions:\n",
    "            ind = self.stockUniverse.index(position.symbol)\n",
    "            stocks[ind] = ( abs(int(float(position.qty))))\n",
    "        \n",
    "        stocks = np.asarray(stocks, dtype = float)\n",
    "        cash = float(self.alpaca.get_account().cash)\n",
    "        self.cash = cash\n",
    "        self.stocks = stocks\n",
    "        self.turbulence_bool = turbulence_bool \n",
    "        self.price = price\n",
    "        \n",
    "        \n",
    "        \n",
    "        amount = np.array(self.cash * (2 ** -12), dtype=np.float32)\n",
    "        scale = np.array(2 ** -6, dtype=np.float32)\n",
    "        state = np.hstack((amount,\n",
    "                    turbulence,\n",
    "                    self.turbulence_bool,\n",
    "                    price * scale,\n",
    "                    self.stocks * scale,\n",
    "                    self.stocks_cd,\n",
    "                    tech,\n",
    "                    )).astype(np.float32)\n",
    "        print(len(self.stockUniverse))\n",
    "        return state\n",
    "        \n",
    "    def submitOrder(self, qty, stock, side, resp):\n",
    "        if(qty > 0):\n",
    "          try:\n",
    "            self.alpaca.submit_order(stock, qty, side, \"market\", \"day\")\n",
    "            print(\"Market order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | completed.\")\n",
    "            resp.append(True)\n",
    "          except:\n",
    "            print(\"Order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | did not go through.\")\n",
    "            resp.append(False)\n",
    "        else:\n",
    "          print(\"Quantity is 0, order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | not completed.\")\n",
    "          resp.append(True)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_sign(ary, thresh):\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
    "\n",
    "        return sigmoid(ary / thresh) * thresh\n",
    "    \n",
    "class StockEnvEmpty(gym.Env):\n",
    "    #Empty Env used for loading rllib agent\n",
    "    def __init__(self,config):\n",
    "      state_dim = config['state_dim']\n",
    "      action_dim = config['action_dim']\n",
    "      self.env_num = 1\n",
    "      self.max_step = 10000\n",
    "      self.env_name = 'StockEnvEmpty'\n",
    "      self.state_dim = state_dim  \n",
    "      self.action_dim = action_dim\n",
    "      self.if_discrete = False  \n",
    "      self.target_return = 9999\n",
    "      self.observation_space = gym.spaces.Box(low=-3000, high=3000, shape=(state_dim,), dtype=np.float32)\n",
    "      self.action_space = gym.spaces.Box(low=-1, high=1, shape=(action_dim,), dtype=np.float32)\n",
    "        \n",
    "    def reset(self):\n",
    "        return \n",
    "\n",
    "    def step(self, actions):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "os4C4-4H7ns7"
   },
   "source": [
    "## Run Paper trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nw0i-0UN3-7",
    "outputId": "264e5160-3fc9-41c4-cc67-04806aa88367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsSBK9ION1t6",
    "outputId": "ecf31b65-9252-4db3-ee94-8a67ce08c847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYtSv6P1N247",
    "outputId": "4b38a9f6-8eea-410e-bbbd-e6b1cb884900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "Kl9nulnAJtiI",
    "outputId": "900cee44-4471-43c7-ad75-b59aad2f6708",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load model models/papertrading/ppo_retrain_1000000.0_2022-01-03_2022-07-19_15Min_20220719-220446\n",
      "Waiting for market to open...\n",
      "Market opened.\n",
      "2022-07-21 07:44:40 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 07:59:53 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 08:15:06 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 08:30:18 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 08:45:31 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 09:00:44 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 09:15:57 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 09:31:09 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 09:46:22 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 10:01:40 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 10:16:55 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 10:32:08 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 10:47:20 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 11:02:33 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 11:17:46 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2022-07-21 11:32:59 [INFO] notebook - Succesfully add technical indicators\n",
      "Successfully transformed into array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\code\\forex\\finrl\\finrl\\finrl_meta\\env_stock_trading\\env_stock_papertrading.py\", line 202, in trade\n",
      "    action = self.model.predict(state)[0]\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 562, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 338, in predict\n",
      "    actions = self._predict(observation, deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 630, in _predict\n",
      "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 659, in get_distribution\n",
      "    return self._get_action_dist_from_latent(latent_pi)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 607, in _get_action_dist_from_latent\n",
      "    return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\", line 152, in proba_distribution\n",
      "    self.distribution = Normal(mean_actions, action_std)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\normal.py\", line 54, in __init__\n",
      "    super(Normal, self).__init__(batch_shape, validate_args=validate_args)\n",
      "  File \"D:\\Anaconda3\\envs\\finrl\\lib\\site-packages\\torch\\distributions\\distribution.py\", line 55, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Expected parameter loc (Tensor of shape (1, 30)) of distribution Normal(loc: torch.Size([1, 30]), scale: torch.Size([1, 30])) to satisfy the constraint Real(), but found invalid values:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "paper_trading_erl = AlpacaPaperTrading(ticker_list = DOW_30_TICKER, \n",
    "                                       time_interval = candle_time_interval, \n",
    "                                       drl_lib = 'stable_baselines3', \n",
    "                                       agent = 'ppo', \n",
    "#                                        cwd = RETRAIN_CWD, \n",
    "                                       cwd='models/papertrading/ppo_retrain_1000000.0_2022-01-03_2022-07-19_15Min_20220719-220446',\n",
    "                                       net_dim = 512, \n",
    "                                       state_dim = state_dim, \n",
    "                                       action_dim= action_dim, \n",
    "                                       API_KEY = API_KEY, \n",
    "                                       API_SECRET = API_SECRET, \n",
    "                                       API_BASE_URL = API_BASE_URL, \n",
    "                                       tech_indicator_list = INDICATORS, \n",
    "                                       turbulence_thresh=30, \n",
    "                                       max_stock=1e2)\n",
    "paper_trading_erl.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srzBZfYEUI1O"
   },
   "source": [
    "# Part 4: Check Portfolio Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "chovN1UhTAht"
   },
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "import exchange_calendars as tc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import yfinance as yf\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime as dt\n",
    "from finrl.plot import backtest_stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CaofxMNCfAR1"
   },
   "outputs": [],
   "source": [
    "def get_trading_days(start, end):\n",
    "    nyse = tc.get_calendar('NYSE')\n",
    "#     df = nyse.sessions_in_range(pd.Timestamp(start,tz=pytz.UTC),\n",
    "#                                 pd.Timestamp(end,tz=pytz.UTC))\n",
    "    df = nyse.sessions_in_range(pd.Timestamp(start),\n",
    "                                pd.Timestamp(end))\n",
    "    trading_days = []\n",
    "    for day in df:\n",
    "        trading_days.append(str(day)[:10])\n",
    "\n",
    "    return trading_days\n",
    "\n",
    "def alpaca_history(key, secret, url, start, end):\n",
    "    api = tradeapi.REST(key, secret, url, 'v2')\n",
    "    trading_days = get_trading_days(start, end)\n",
    "    df = pd.DataFrame()\n",
    "    for day in trading_days:\n",
    "#         df = df.append(api.get_portfolio_history(date_start = day,timeframe='5Min').df.iloc[:78])\n",
    "        df = pd.concat([df, api.get_portfolio_history(date_start = day,timeframe='5Min').df.iloc[:78]])\n",
    "    equities = df.equity.values\n",
    "    cumu_returns = equities/equities[0]\n",
    "    cumu_returns = cumu_returns[~np.isnan(cumu_returns)]\n",
    "    \n",
    "    return df, cumu_returns\n",
    "\n",
    "def DIA_history(start):\n",
    "    data_df = yf.download(['^DJI'],start=start, interval=\"5m\")\n",
    "    data_df = data_df.iloc[48:]\n",
    "    baseline_returns = data_df['Adj Close'].values/data_df['Adj Close'].values[0]\n",
    "    return data_df, baseline_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CHiZRVpURpx"
   },
   "source": [
    "## Get cumulative return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O_YT7v-LSdfV"
   },
   "outputs": [],
   "source": [
    "history_start_date='2022-07-19'\n",
    "history_end_date='2022-07-20'\n",
    "\n",
    "df_erl, cumu_erl = alpaca_history(key=API_KEY, \n",
    "                                  secret=API_SECRET, \n",
    "                                  url=API_BASE_URL, \n",
    "                                  start=history_start_date, #must be within 1 month\n",
    "                                  end='2022-07-20') #change the date if error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMcQjwHOS6Zb",
    "outputId": "aff51b64-6166-4bdd-e3f7-1b71fb482520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df_djia, cumu_djia = DIA_history(start=history_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_6OhFfTTGte",
    "outputId": "9ce71a5b-8707-4979-cf4f-213377a74599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           profit_loss  profit_loss_pct     equity\n",
      "timestamp                                                         \n",
      "2022-07-19 09:30:00-04:00         0.00         0.000000  100000.00\n",
      "2022-07-19 09:35:00-04:00         0.00         0.000000  100000.00\n",
      "2022-07-19 09:40:00-04:00         0.00         0.000000  100000.00\n",
      "2022-07-19 09:45:00-04:00         0.00         0.000000  100000.00\n",
      "2022-07-19 09:50:00-04:00         0.00         0.000000  100000.00\n",
      "...                                ...              ...        ...\n",
      "2022-07-20 15:35:00-04:00       -78.88        -0.000787  100131.16\n",
      "2022-07-20 15:40:00-04:00       -82.38        -0.000822  100127.66\n",
      "2022-07-20 15:45:00-04:00       -62.37        -0.000622  100147.67\n",
      "2022-07-20 15:50:00-04:00       -65.54        -0.000654  100144.50\n",
      "2022-07-20 15:55:00-04:00       -74.84        -0.000747  100135.20\n",
      "\n",
      "[156 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_erl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aURLl8M0TKHf",
    "outputId": "adb38549-a994-453f-9a04-f85f48fd4704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Open          High           Low  \\\n",
      "Datetime                                                              \n",
      "2022-07-19 13:30:00-04:00  31630.939453  31653.740234  31630.939453   \n",
      "2022-07-19 13:35:00-04:00  31653.759766  31699.070312  31652.710938   \n",
      "2022-07-19 13:40:00-04:00  31699.640625  31724.500000  31698.679688   \n",
      "2022-07-19 13:45:00-04:00  31724.730469  31727.679688  31710.900391   \n",
      "2022-07-19 13:50:00-04:00  31711.240234  31718.080078  31700.169922   \n",
      "...                                 ...           ...           ...   \n",
      "2022-07-20 15:35:00-04:00  31870.050781  31885.789062  31857.500000   \n",
      "2022-07-20 15:40:00-04:00  31870.310547  31925.939453  31864.169922   \n",
      "2022-07-20 15:45:00-04:00  31914.439453  31928.199219  31882.820312   \n",
      "2022-07-20 15:50:00-04:00  31910.259766  31929.730469  31867.650391   \n",
      "2022-07-20 15:55:00-04:00  31876.099609  31896.429688  31857.269531   \n",
      "\n",
      "                                  Close     Adj Close    Volume  \n",
      "Datetime                                                         \n",
      "2022-07-19 13:30:00-04:00  31653.740234  31653.740234   2572499  \n",
      "2022-07-19 13:35:00-04:00  31699.000000  31699.000000   2851058  \n",
      "2022-07-19 13:40:00-04:00  31724.470703  31724.470703   3263087  \n",
      "2022-07-19 13:45:00-04:00  31710.929688  31710.929688   3045335  \n",
      "2022-07-19 13:50:00-04:00  31709.060547  31709.060547   2687191  \n",
      "...                                 ...           ...       ...  \n",
      "2022-07-20 15:35:00-04:00  31870.089844  31870.089844   4114640  \n",
      "2022-07-20 15:40:00-04:00  31914.210938  31914.210938   4594436  \n",
      "2022-07-20 15:45:00-04:00  31910.820312  31910.820312   5458338  \n",
      "2022-07-20 15:50:00-04:00  31876.660156  31876.660156   8790412  \n",
      "2022-07-20 15:55:00-04:00  31870.169922  31870.169922  16991018  \n",
      "\n",
      "[108 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_djia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "PJXPwmx9Ts5o",
    "outputId": "a4fddc2b-529f-469d-dbc6-4261947a1d84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profit_loss</th>\n",
       "      <th>profit_loss_pct</th>\n",
       "      <th>equity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-20 15:35:00-04:00</th>\n",
       "      <td>-78.88</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>100131.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-20 15:40:00-04:00</th>\n",
       "      <td>-82.38</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>100127.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-20 15:45:00-04:00</th>\n",
       "      <td>-62.37</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>100147.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-20 15:50:00-04:00</th>\n",
       "      <td>-65.54</td>\n",
       "      <td>-0.000654</td>\n",
       "      <td>100144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-20 15:55:00-04:00</th>\n",
       "      <td>-74.84</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>100135.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           profit_loss  profit_loss_pct     equity\n",
       "timestamp                                                         \n",
       "2022-07-20 15:35:00-04:00       -78.88        -0.000787  100131.16\n",
       "2022-07-20 15:40:00-04:00       -82.38        -0.000822  100127.66\n",
       "2022-07-20 15:45:00-04:00       -62.37        -0.000622  100147.67\n",
       "2022-07-20 15:50:00-04:00       -65.54        -0.000654  100144.50\n",
       "2022-07-20 15:55:00-04:00       -74.84        -0.000747  100135.20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_erl.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1Iaw90FTNfU",
    "outputId": "cb50261c-34d2-49d8-d2d1-6a14a5995b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of erl return:  156\n",
      "len of dia return:  108\n"
     ]
    }
   ],
   "source": [
    "returns_erl = cumu_erl -1 \n",
    "returns_dia = cumu_djia - 1\n",
    "returns_dia = returns_dia[:returns_erl.shape[0]]\n",
    "print('len of erl return: ', returns_erl.shape[0])\n",
    "print('len of dia return: ', returns_dia.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z0LEm7KUZ5W"
   },
   "source": [
    "## plot and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Foqk1wIQTQJ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Super\\AppData\\Local\\Temp\\ipykernel_40360\\3373249749.py:19: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=1000)\n",
    "plt.grid()\n",
    "plt.grid(which='minor', axis='y')\n",
    "plt.title('Stock Trading (Paper trading)', fontsize=20)\n",
    "plt.plot(returns_erl, label = 'ElegantRL Agent', color = 'red')\n",
    "#plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )\n",
    "#plt.plot(returns_rllib, label = 'RLlib Agent', color = 'green')\n",
    "plt.plot(returns_dia, label = 'DJIA', color = 'grey')\n",
    "plt.ylabel('Return', fontsize=16)\n",
    "plt.xlabel('Year 2022', fontsize=16)\n",
    "plt.xticks(size = 14)\n",
    "plt.yticks(size = 14)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(78))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n",
    "                                                    '','10-21','','10-22']))\n",
    "plt.legend(fontsize=10.5)\n",
    "plt.savefig('papertrading_stock.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FinRL_PaperTrading_Demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
